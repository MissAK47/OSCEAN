# 【模块检查方案06】工作流引擎模块重构方案

## 📋 1. 关键问题发现：boost崩溃与数据流处理错误

### 1.1 **❌ 问题一：boost崩溃根本原因**

#### **发现的符号冲突和混用问题**
```cpp
// ❌ 文件: workflow_engine.h:3-17
// 定义boost宏但实际使用std::future，造成符号冲突
#ifndef BOOST_THREAD_PROVIDES_FUTURE
#define BOOST_THREAD_PROVIDES_FUTURE
#endif
// ... 更多boost宏定义

#include <boost/thread/future.hpp>  // 引入boost但不使用

// ❌ 但实际接口使用std::future
std::future<WorkflowContext> submitWorkflow(...);  // 应该是boost::future
```

#### **崩溃的技术原因**
1. **符号冲突**：boost宏定义影响std::future的编译
2. **内存管理冲突**：boost和std的future内存模型不兼容
3. **线程调度冲突**：boost::thread与std::thread混用导致死锁

### 1.2 **❌ 问题二：数据管理工作流处理严重错误**

#### **无法控制的并发爆炸**
```cpp
// ❌ 文件: data_management_workflow.cpp:219-250
std::vector<std::future<...>> futures;

for (const auto& filePath : discoveryResult.candidateFiles) {  // 可能数千个文件
    futures.emplace_back(std::async(std::launch::async, [...]() {  // 无限制创建线程
        return std::make_pair(filePath, this->validateFile(filePath));
    }));
    
    if (futures.size() >= config_.maxConcurrentFiles) {  // 例如>=10
        for (auto& future : futures) {
            auto result = future.get();  // ❌ 同步等待破坏并发性
        }
        futures.clear();  // ❌ 丢失结果
    }
}
```

**❌ 严重后果**：
- 处理1000个文件时创建1000个线程，系统崩溃
- 内存无限制增长
- 无法正确收集和合并处理结果
- 没有错误恢复机制

### 1.3 **❌ 问题三：依赖服务调用方式错误**

#### **直接调用造成阻塞**
```cpp
// ❌ 错误的服务调用方式
auto metadata = dataAccessService_->getFileMetadata(filePath);  // 阻塞调用
if (!metadata.has_value()) {
    // 处理失败
}
```

**❌ 问题**：没有使用服务的异步接口，造成工作流线程阻塞。

## 🎯 2. 重构目标：彻底解决boost兼容性与工作流正确性

### 2.1 **核心重构原则**
1. **彻底消除boost/std混用**：要么全用boost，要么全用std
2. **正确实现并发控制**：使用线程池而非无限制创建线程
3. **异步服务调用**：正确使用核心服务的异步接口
4. **完整错误处理**：处理所有可能的异常和错误场景
5. **资源管理**：确保内存和文件句柄正确释放

### 2.2 **解决方案A：完全使用std（推荐）**
基于稳定性考虑，建议完全使用std::future，移除所有boost依赖。

### 2.3 **解决方案B：完全使用boost（备选）**
如果需要boost的高级特性，则彻底切换到boost实现。

## 🔧 3. 方案A：完全std实现（推荐方案）

### 3.1 阶段一：移除boost依赖与修正接口

#### **3.1.1 头文件清理**
```cpp
// 文件: include/workflow_engine/workflow_engine.h

#pragma once

// ✅ 移除所有boost相关内容
#include "workflow_types.h"
#include "workflow_base.h"
#include <string>
#include <memory>
#include <map>
#include <functional>
#include <future>       // ✅ 只使用std::future
#include <queue>
#include <mutex>
#include <shared_mutex>
#include <condition_variable>
#include <thread>
#include <atomic>

namespace workflow_engine {

/**
 * @brief 工作流工厂函数类型
 */
using WorkflowFactory = std::function<std::unique_ptr<WorkflowBase>()>;

/**
 * @class WorkflowEngine
 * @brief 通用工作流引擎（纯std实现）
 */
class WorkflowEngine {
public:
    explicit WorkflowEngine(const WorkflowEngineConfig& config = WorkflowEngineConfig{});
    ~WorkflowEngine();

    bool start();
    void stop();
    
    bool registerWorkflow(const std::string& workflowType, WorkflowFactory factory);
    bool unregisterWorkflow(const std::string& workflowType);

    /**
     * @brief 提交工作流执行
     * @param workflowType 工作流类型
     * @param context 工作流上下文
     * @return 工作流执行的std::future对象
     */
    std::future<WorkflowContext> submitWorkflow(const std::string& workflowType, 
                                               WorkflowContext context);

    /**
     * @brief 异步执行工作流
     * @param workflowType 工作流类型
     * @param context 工作流上下文
     * @param callback 完成回调函数
     * @return 工作流ID
     */
    std::string executeWorkflowAsync(const std::string& workflowType,
                                   WorkflowContext context,
                                   std::function<void(const WorkflowContext&)> callback = nullptr);

    WorkflowContext executeWorkflowSync(const std::string& workflowType, 
                                      WorkflowContext context);

    bool cancelWorkflow(const std::string& workflowId);
    std::optional<WorkflowContext> getWorkflowStatus(const std::string& workflowId);
    std::vector<WorkflowContext> getRunningWorkflows();
    
    struct EngineStatistics {
        int totalWorkflowsExecuted = 0;
        int currentRunningWorkflows = 0;
        int queuedWorkflows = 0;
        int successfulWorkflows = 0;
        int failedWorkflows = 0;
        int cancelledWorkflows = 0;
        double averageExecutionTime = 0.0;
    };
    EngineStatistics getStatistics() const;

    void setGlobalProgressCallback(ProgressCallback callback);
    bool isWorkflowRegistered(const std::string& workflowType) const;
    std::vector<std::string> getRegisteredWorkflowTypes() const;
    void cleanupCompletedWorkflows(std::chrono::minutes maxAge = std::chrono::minutes{60});

private:
    struct WorkflowTask {
        std::string workflowId;
        std::string workflowType;
        WorkflowContext context;
        std::promise<WorkflowContext> promise;                           // ✅ std::promise
        std::function<void(const WorkflowContext&)> callback;
        std::chrono::system_clock::time_point submitTime;
        std::unique_ptr<WorkflowBase> workflow;
    };

    // 配置和状态
    WorkflowEngineConfig config_;
    std::atomic<bool> running_{false};
    
    // 工作流工厂
    std::map<std::string, WorkflowFactory> workflowFactories_;
    mutable std::shared_mutex factoriesMutex_;
    
    // 任务队列和线程管理
    std::queue<std::unique_ptr<WorkflowTask>> taskQueue_;
    std::mutex queueMutex_;
    std::condition_variable queueCondition_;
    
    std::vector<std::thread> workerThreads_;                            // ✅ std::thread
    
    // 运行中的工作流
    std::map<std::string, std::unique_ptr<WorkflowTask>> runningWorkflows_;
    std::mutex runningMutex_;
    
    // 已完成的工作流
    std::map<std::string, WorkflowContext> completedWorkflows_;
    mutable std::shared_mutex completedMutex_;
    
    // 统计信息
    mutable std::mutex statisticsMutex_;
    EngineStatistics statistics_;
    
    // 全局回调
    ProgressCallback globalProgressCallback_;
    
    void workerThread();
    void executeTask(std::unique_ptr<WorkflowTask> task);
    std::string generateWorkflowId();
    void updateStatistics(WorkflowStatus result, std::chrono::milliseconds duration);
    void cleanupWorkerThreads();
};

} // namespace workflow_engine
```

#### **3.1.2 CMakeLists.txt修正**
```cmake
# 文件: CMakeLists.txt

cmake_minimum_required(VERSION 3.16)
project(WorkflowEngine VERSION 3.0.0 LANGUAGES CXX)

set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# 编译器特定设置
if(MSVC)
    add_compile_options(/W4 /EHsc)
    add_compile_definitions(_CRT_SECURE_NO_WARNINGS)
else()
    add_compile_options(-Wall -Wextra -Wpedantic)
endif()

# 设置包含目录
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_SOURCE_DIR}/../core_service_interfaces/include
    ${CMAKE_CURRENT_SOURCE_DIR}/../common_utilities/include
    ${CMAKE_CURRENT_SOURCE_DIR}/../core_services_impl/metadata_service/include
    ${CMAKE_CURRENT_SOURCE_DIR}/../core_services_impl/data_access_service/include
    ${CMAKE_CURRENT_SOURCE_DIR}/../core_services_impl/crs_service/include
)

# ✅ 只查找线程库，移除boost依赖
find_package(Threads REQUIRED)

# 源文件
set(WORKFLOW_ENGINE_SOURCES
    src/workflow_types.cpp
    src/workflow_base.cpp
    src/workflow_engine.cpp
    src/data_management_workflow.cpp
)

# 创建静态库
add_library(workflow_engine STATIC ${WORKFLOW_ENGINE_SOURCES})

# ✅ 只链接线程库
target_link_libraries(workflow_engine 
    PRIVATE 
    Threads::Threads
)

# 测试可执行文件也移除boost依赖
add_executable(workflow_test_existing tests/test_workflow_functionality.cpp)
target_link_libraries(workflow_test_existing 
    workflow_engine
    Threads::Threads
)

add_executable(workflow_integration_test tests/test_integration_full.cpp)
target_link_libraries(workflow_integration_test 
    workflow_engine
    Threads::Threads
)

add_executable(workflow_integration_with_services tests/test_integration_with_services.cpp)
target_link_libraries(workflow_integration_with_services 
    workflow_engine
    data_access_service
    crs_service
    Threads::Threads
)

add_executable(workflow_complete_integration tests/test_complete_integration.cpp)
target_link_libraries(workflow_complete_integration 
    workflow_engine
    data_access_service
    crs_service
    metadata_service
    Threads::Threads
)

# 设置输出目录
set_target_properties(workflow_engine PROPERTIES
    ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib
)

set_target_properties(workflow_test_existing PROPERTIES
    RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin
)

set_target_properties(workflow_integration_test PROPERTIES
    RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin
)

set_target_properties(workflow_integration_with_services PROPERTIES
    RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin
)

set_target_properties(workflow_complete_integration PROPERTIES
    RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin
)
```

### 3.2 阶段二：数据管理工作流正确并发实现

#### **3.2.1 线程池管控的并发处理**
```cpp
// 文件: src/data_management_workflow.cpp

#include "workflow_engine/workflows/data_management_workflow.h"
#include <iostream>
#include <filesystem>
#include <fstream>
#include <algorithm>
#include <future>         // ✅ 只使用std
#include <chrono>
#include <regex>
#include <iomanip>
#include <sstream>
#include <thread>

namespace workflow_engine {
namespace workflows {

DataManagementWorkflow::DataManagementWorkflow(const DataManagementWorkflowConfig& config)
    : WorkflowBase("DataManagement"), config_(config) {
}

// ✅ 正确的异步数据验证实现
WorkflowResult DataManagementWorkflow::executeDataValidation(WorkflowContext& context) {
    try {
        auto discoveryIt = context.results.find("dataDiscoveryResult");
        if (discoveryIt == context.results.end()) {
            addError(context, "未找到数据发现结果");
            return WorkflowResult::Failed;
        }
        
        auto discoveryResult = std::any_cast<DataDiscoveryResult>(discoveryIt->second);
        
        DataValidationResult result;
        result.totalFilesChecked = discoveryResult.candidateFiles.size();
        
        addLog(context, "INFO", "开始验证 " + std::to_string(result.totalFilesChecked) + " 个文件");
        
        // ✅ 使用受控的并发处理
        if (executeDataValidationConcurrent(discoveryResult.candidateFiles, result, context) 
            != WorkflowResult::Success) {
            return WorkflowResult::Failed;
        }
        
        context.results["dataValidationResult"] = result;
        
        addLog(context, "INFO", "数据验证完成: " + 
               std::to_string(result.validFilesCount) + "/" + 
               std::to_string(result.totalFilesChecked) + " 文件有效");
        
        return WorkflowResult::Success;
        
    } catch (const std::exception& e) {
        addError(context, "数据验证失败: " + std::string(e.what()));
        return WorkflowResult::Failed;
    }
}

WorkflowResult DataManagementWorkflow::executeDataValidationConcurrent(
    const std::vector<std::string>& filePaths,
    DataValidationResult& result,
    WorkflowContext& context) {
    
    const size_t maxConcurrent = config_.maxConcurrentFiles;
    const size_t totalFiles = filePaths.size();
    
    // ✅ 受控并发：分批处理
    for (size_t startIdx = 0; startIdx < totalFiles; startIdx += maxConcurrent) {
        if (shouldCancel(context)) {
            addWarning(context, "验证过程被取消");
            return WorkflowResult::Failed;
        }
        
        size_t endIdx = std::min(startIdx + maxConcurrent, totalFiles);
        size_t batchSize = endIdx - startIdx;
        
        addLog(context, "INFO", "处理批次 " + std::to_string(startIdx / maxConcurrent + 1) + 
               ", 文件 " + std::to_string(startIdx + 1) + "-" + std::to_string(endIdx) + 
               "/" + std::to_string(totalFiles));
        
        // ✅ 创建当前批次的futures
        std::vector<std::future<std::pair<std::string, std::pair<bool, std::string>>>> batchFutures;
        batchFutures.reserve(batchSize);
        
        // 启动当前批次的任务
        for (size_t i = startIdx; i < endIdx; ++i) {
            const std::string& filePath = filePaths[i];
            
            batchFutures.emplace_back(
                std::async(std::launch::async, [this, filePath]() -> std::pair<std::string, std::pair<bool, std::string>> {
                    try {
                        auto validation = validateFile(filePath);
                        return std::make_pair(filePath, validation);
                    } catch (const std::exception& e) {
                        return std::make_pair(filePath, std::make_pair(false, 
                                            "验证异常: " + std::string(e.what())));
                    }
                })
            );
        }
        
        // ✅ 等待当前批次完成并收集结果
        for (auto& future : batchFutures) {
            try {
                auto [filePath, validation] = future.get();
                auto [isValid, errorMsg] = validation;
                
                if (isValid) {
                    result.validFiles.push_back(filePath);
                    result.validFilesCount++;
                } else {
                    result.invalidFiles.push_back(filePath);
                    result.validationErrors[filePath] = errorMsg;
                    addWarning(context, "文件验证失败: " + filePath + " - " + errorMsg);
                }
                
            } catch (const std::exception& e) {
                addError(context, "获取验证结果失败: " + std::string(e.what()));
                // 继续处理其他文件
            }
        }
        
        // ✅ 报告进度
        double progress = static_cast<double>(endIdx) / totalFiles * 100.0;
        updateProgress(context, WorkflowStage::DataValidation, 
                      "已验证 " + std::to_string(endIdx) + "/" + std::to_string(totalFiles) + 
                      " 文件 (" + std::to_string(static_cast<int>(progress)) + "%)");
    }
    
    return WorkflowResult::Success;
}

// ✅ 正确的异步元数据提取实现
WorkflowResult DataManagementWorkflow::executeMetadataExtraction(WorkflowContext& context) {
    try {
        auto validationIt = context.results.find("dataValidationResult");
        if (validationIt == context.results.end()) {
            addError(context, "未找到数据验证结果");
            return WorkflowResult::Failed;
        }
        
        auto validationResult = std::any_cast<DataValidationResult>(validationIt->second);
        
        MetadataExtractionResult result;
        result.totalFilesProcessed = validationResult.validFiles.size();
        
        addLog(context, "INFO", "开始提取 " + std::to_string(result.totalFilesProcessed) + " 个文件的元数据");
        
        // ✅ 使用异步服务调用进行元数据提取
        if (executeMetadataExtractionAsync(validationResult.validFiles, result, context) 
            != WorkflowResult::Success) {
            return WorkflowResult::Failed;
        }
        
        context.results["metadataExtractionResult"] = result;
        
        addLog(context, "INFO", "元数据提取完成: " + 
               std::to_string(result.successfulExtractions) + "/" + 
               std::to_string(result.totalFilesProcessed) + " 文件成功");
        
        return WorkflowResult::Success;
        
    } catch (const std::exception& e) {
        addError(context, "元数据提取失败: " + std::string(e.what()));
        return WorkflowResult::Failed;
    }
}

WorkflowResult DataManagementWorkflow::executeMetadataExtractionAsync(
    const std::vector<std::string>& validFiles,
    MetadataExtractionResult& result,
    WorkflowContext& context) {
    
    const size_t maxConcurrent = config_.maxConcurrentFiles;
    const size_t totalFiles = validFiles.size();
    
    // ✅ 受控并发元数据提取
    for (size_t startIdx = 0; startIdx < totalFiles; startIdx += maxConcurrent) {
        if (shouldCancel(context)) {
            addWarning(context, "元数据提取被取消");
            return WorkflowResult::Failed;
        }
        
        size_t endIdx = std::min(startIdx + maxConcurrent, totalFiles);
        size_t batchSize = endIdx - startIdx;
        
        addLog(context, "INFO", "提取元数据批次 " + std::to_string(startIdx / maxConcurrent + 1) + 
               ", 文件 " + std::to_string(startIdx + 1) + "-" + std::to_string(endIdx) + 
               "/" + std::to_string(totalFiles));
        
        // ✅ 创建当前批次的异步元数据提取任务
        std::vector<std::future<std::pair<std::string, std::optional<FileMetadata>>>> metadataFutures;
        metadataFutures.reserve(batchSize);
        
        // 启动当前批次的元数据提取任务
        for (size_t i = startIdx; i < endIdx; ++i) {
            const std::string& filePath = validFiles[i];
            
            metadataFutures.emplace_back(
                std::async(std::launch::async, [this, filePath]() -> std::pair<std::string, std::optional<FileMetadata>> {
                    try {
                        // ✅ 正确使用数据访问服务的异步接口
                        if (dataAccessService_) {
                            auto metadataFuture = dataAccessService_->getFileMetadataAsync(filePath);
                            auto metadata = metadataFuture.get();  // 等待异步结果
                            return std::make_pair(filePath, metadata);
                        } else {
                            // ✅ 备用：简化元数据提取
                            auto simpleMetadata = extractSimpleMetadata(filePath);
                            return std::make_pair(filePath, simpleMetadata);
                        }
                    } catch (const std::exception& e) {
                        // 记录错误但不中断整个过程
                        return std::make_pair(filePath, std::nullopt);
                    }
                })
            );
        }
        
        // ✅ 等待当前批次完成并收集元数据结果
        for (auto& future : metadataFutures) {
            try {
                auto [filePath, metadata] = future.get();
                
                if (metadata.has_value()) {
                    result.extractedMetadata[filePath] = metadata.value();
                    result.successfulExtractions++;
                    
                    // 存储到元数据服务（如果可用）
                    if (metadataService_) {
                        try {
                            auto storeResult = metadataService_->storeFileMetadataAsync(filePath, metadata.value());
                            storeResult.get();  // 等待存储完成
                        } catch (const std::exception& e) {
                            addWarning(context, "元数据存储失败: " + filePath + " - " + std::string(e.what()));
                        }
                    }
                } else {
                    result.extractionErrors[filePath] = "元数据提取失败";
                    addWarning(context, "元数据提取失败: " + filePath);
                }
                
            } catch (const std::exception& e) {
                addError(context, "获取元数据结果失败: " + std::string(e.what()));
            }
        }
        
        // ✅ 报告进度
        double progress = static_cast<double>(endIdx) / totalFiles * 100.0;
        updateProgress(context, WorkflowStage::MetadataExtraction, 
                      "已提取 " + std::to_string(endIdx) + "/" + std::to_string(totalFiles) + 
                      " 文件元数据 (" + std::to_string(static_cast<int>(progress)) + "%)");
    }
    
    return WorkflowResult::Success;
}

// ✅ 简化元数据提取的备用实现
std::optional<FileMetadata> DataManagementWorkflow::extractSimpleMetadata(const std::string& filePath) {
    try {
        FileMetadata metadata;
        metadata.filePath = filePath;
        metadata.fileName = std::filesystem::path(filePath).filename().string();
        metadata.fileSize = std::filesystem::file_size(filePath);
        metadata.format = detectFileFormat(filePath);
        metadata.lastModified = std::chrono::system_clock::now();
        
        // 基本地理信息提取（简化版本）
        if (metadata.format == "NetCDF") {
            extractNetCDFBasicInfo(filePath, metadata);
        } else if (metadata.format == "GeoTIFF") {
            extractGeoTIFFBasicInfo(filePath, metadata);
        }
        
        return metadata;
        
    } catch (const std::exception& e) {
        return std::nullopt;
    }
}

void DataManagementWorkflow::extractNetCDFBasicInfo(const std::string& filePath, FileMetadata& metadata) {
    // ✅ 简化的NetCDF信息提取
    try {
        // 这里可以使用NetCDF库进行基本信息读取
        // 暂时使用文件名解析等简单方法
        
        auto filename = std::filesystem::path(filePath).filename().string();
        
        // 尝试从文件名解析日期信息
        std::regex datePattern(R"((\d{4})(\d{2})(\d{2}))");
        std::smatch match;
        if (std::regex_search(filename, match, datePattern)) {
            // 解析到日期信息
            metadata.temporalRange.startTime = std::chrono::system_clock::now();  // 简化实现
            metadata.temporalRange.endTime = metadata.temporalRange.startTime;
        }
        
        // 设置基本范围（需要实际读取文件获取）
        metadata.extent.minX = -180.0;
        metadata.extent.maxX = 180.0;
        metadata.extent.minY = -90.0;
        metadata.extent.maxY = 90.0;
        
    } catch (const std::exception& e) {
        // 忽略解析错误，保持基本信息
    }
}

void DataManagementWorkflow::extractGeoTIFFBasicInfo(const std::string& filePath, FileMetadata& metadata) {
    // ✅ 简化的GeoTIFF信息提取
    try {
        // 这里可以使用GDAL库进行基本信息读取
        // 暂时设置默认值
        
        metadata.extent.minX = 0.0;
        metadata.extent.maxX = 1.0;
        metadata.extent.minY = 0.0;
        metadata.extent.maxY = 1.0;
        
    } catch (const std::exception& e) {
        // 忽略解析错误
    }
}

} // namespace workflows
} // namespace workflow_engine
```

## 📊 4. 方案B：完全boost实现（备选方案）

### 4.1 boost完整实现
```cpp
// 文件: include/workflow_engine/workflow_engine_boost.h

#pragma once

// ✅ 正确的boost配置
#define BOOST_THREAD_PROVIDES_FUTURE
#define BOOST_THREAD_PROVIDES_FUTURE_CONTINUATION
#define BOOST_THREAD_PROVIDES_FUTURE_WHEN_ALL_WHEN_ANY
#define BOOST_THREAD_PROVIDES_FUTURE_ASYNC

#include <boost/thread/future.hpp>
#include <boost/asio/thread_pool.hpp>
#include <boost/asio/post.hpp>

namespace workflow_engine {

class WorkflowEngineBoost {
public:
    explicit WorkflowEngineBoost(const WorkflowEngineConfig& config = WorkflowEngineConfig{});
    ~WorkflowEngineBoost();

    /**
     * @brief 提交工作流执行（boost版本）
     * @param workflowType 工作流类型
     * @param context 工作流上下文
     * @return boost::future对象
     */
    boost::future<WorkflowContext> submitWorkflow(const std::string& workflowType, 
                                                 WorkflowContext context);

    /**
     * @brief 批量提交工作流（boost高级特性）
     * @param requests 多个工作流请求
     * @return 所有工作流的future
     */
    boost::future<std::vector<WorkflowContext>> submitWorkflowBatch(
        const std::vector<std::pair<std::string, WorkflowContext>>& requests);

private:
    WorkflowEngineConfig config_;
    std::unique_ptr<boost::asio::thread_pool> threadPool_;
    
    struct WorkflowTaskBoost {
        std::string workflowId;
        std::string workflowType;
        WorkflowContext context;
        boost::promise<WorkflowContext> promise;                      // ✅ boost::promise
        std::function<void(const WorkflowContext&)> callback;
        std::chrono::system_clock::time_point submitTime;
        std::unique_ptr<WorkflowBase> workflow;
    };
};

} // namespace workflow_engine
```

## 📋 5. 重构检查清单

### 5.1 boost兼容性修正 ✅
- [ ] **完全移除boost依赖**: 删除所有boost头文件和宏定义
- [ ] **std::future统一**: 所有异步接口使用std::future/std::promise
- [ ] **CMakeLists清理**: 移除Boost::thread链接依赖
- [ ] **编译验证**: 确保所有目标编译通过，无符号冲突

### 5.2 数据管理工作流正确性 ✅
- [ ] **受控并发**: 实现基于批次的并发控制，不再无限制创建线程
- [ ] **异步服务调用**: 正确使用核心服务的异步接口
- [ ] **结果收集**: 完整收集和合并所有批次的处理结果
- [ ] **错误处理**: 每个环节都有完整的异常处理和恢复机制
- [ ] **进度报告**: 实时准确报告处理进度

### 5.3 资源管理优化 ✅
- [ ] **内存控制**: 批次处理确保内存使用可控
- [ ] **线程池使用**: 使用std::async的合理线程池
- [ ] **文件句柄管理**: 确保文件操作后正确关闭句柄
- [ ] **异常安全**: 所有资源在异常情况下正确释放

### 5.4 性能验证 ✅
- [ ] **并发性能**: 验证新的批次并发模式性能
- [ ] **内存效率**: 验证内存使用不再无限制增长
- [ ] **错误恢复**: 验证异常情况下的恢复能力
- [ ] **大规模测试**: 使用1000+文件测试稳定性

---

**重构总结**: 工作流引擎的boost崩溃问题根源在于std/boost混用导致的符号冲突。推荐方案A彻底移除boost依赖，使用纯std实现，同时修正数据管理工作流的并发控制逻辑，实现真正的受控并发处理。重构后将彻底解决崩溃问题，并提供正确、高效、稳定的工作流处理能力。 