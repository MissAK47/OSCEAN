/**
 * @file unified_thread_pool_manager.h
 * @brief ç»Ÿä¸€çº¿ç¨‹æ± ç®¡ç†å™¨ - æ™ºèƒ½èµ„æºç®¡ç†å’Œä»»åŠ¡è°ƒåº¦
 * 
 * ğŸ¯ æ ¸å¿ƒç›®æ ‡ï¼š
 * âœ… ç»Ÿä¸€çº¿ç¨‹æ± ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œè§£å†³ææ„å¡æ­»é—®é¢˜
 * âœ… æ™ºèƒ½ä»»åŠ¡è°ƒåº¦ï¼Œé¿å…èµ„æºç«äº‰
 * âœ… æ”¯æŒæµ‹è¯•æ¨¡å¼çš„ä¼˜é›…é€€åŒ–
 * âœ… é«˜æ•ˆçš„å¤šæ–‡ä»¶å¹¶å‘å¤„ç†
 * 
 * ğŸ”§ è®¾è®¡åŸåˆ™ï¼š
 * - å…±äº«è€Œéç‹¬å ï¼šæ‰€æœ‰æ¨¡å—å…±äº«ç»Ÿä¸€çš„çº¿ç¨‹æ± 
 * - æ™ºèƒ½è€Œéå¼ºåˆ¶ï¼šæ ¹æ®ä»»åŠ¡ç‰¹æ€§æ™ºèƒ½è°ƒåº¦
 * - ä¼˜é›…è€Œéç²—æš´ï¼šæ¸è¿›å¼å…³é—­ï¼Œé¿å…å¼ºåˆ¶ç­‰å¾…
 */

#pragma once

// å¯ç”¨boost::asioæ”¯æŒ
#define OSCEAN_ENABLE_BOOST_ASIO
#include "../utilities/boost_config.h"
OSCEAN_ENABLE_BOOST_ASIO_IN_MODULE();  // çº¿ç¨‹æ± ç®¡ç†å™¨éœ€è¦ä½¿ç”¨boost::asio

#include "../async/async_framework.h"
#include <boost/asio/thread_pool.hpp>
#include <boost/asio/post.hpp>
#include <boost/thread/future.hpp>

#include <memory>
#include <string>
#include <vector>
#include <functional>
#include <atomic>
#include <thread>
#include <mutex>
#include <shared_mutex>
#include <map>
#include <unordered_map>
#include <unordered_set>
#include <chrono>
#include <queue>
#include <condition_variable>

namespace oscean::common_utils::infrastructure {

/**
 * @brief ä»»åŠ¡ç±»å‹ - ç”¨äºæ™ºèƒ½è°ƒåº¦
 */
enum class TaskType {
    CPU_INTENSIVE,      // CPUå¯†é›†å‹ï¼šæ•°å€¼è®¡ç®—ã€åæ ‡è½¬æ¢
    IO_BOUND,          // I/Oå¯†é›†å‹ï¼šæ–‡ä»¶è¯»å†™ã€ç½‘ç»œè¯·æ±‚
    MEMORY_INTENSIVE,   // å†…å­˜å¯†é›†å‹ï¼šå¤§æ•°æ®å¤„ç†ã€ç¼“å­˜æ“ä½œ
    QUICK_TASK,        // å¿«é€Ÿä»»åŠ¡ï¼šå…ƒæ•°æ®æŸ¥è¯¢ã€ç®€å•è®¡ç®—
    BACKGROUND,        // åå°ä»»åŠ¡ï¼šæ¸…ç†ã€ç»Ÿè®¡
    INTERACTIVE        // äº¤äº’ä»»åŠ¡ï¼šç”¨æˆ·è¯·æ±‚å“åº”
};

/**
 * @brief ä»»åŠ¡ä¼˜å…ˆçº§
 */
enum class TaskPriority {
    LOW = 0,
    NORMAL = 1,
    HIGH = 2,
    CRITICAL = 3
};

/**
 * @brief ğŸ”§ æ™ºèƒ½ä»»åŠ¡è°ƒåº¦å™¨
 */
class IntelligentTaskScheduler {
public:
    struct TaskInfo {
        std::string taskId;
        TaskType type;
        TaskPriority priority;
        std::chrono::steady_clock::time_point submitTime;
        std::vector<std::string> resourceHints;  // èµ„æºæç¤ºï¼ˆå¦‚æ–‡ä»¶è·¯å¾„ï¼‰
        size_t estimatedDurationMs = 0;
    };
    
    /**
     * @brief é€‰æ‹©æœ€ä½³çº¿ç¨‹æ± 
     */
    size_t selectOptimalPool(const TaskInfo& task, const std::vector<size_t>& availableThreads) const;
    
    /**
     * @brief æ£€æŸ¥èµ„æºå†²çª
     */
    bool hasResourceConflict(const TaskInfo& newTask, const std::vector<TaskInfo>& runningTasks) const;
    
    /**
     * @brief å»ºè®®ä»»åŠ¡å»¶è¿Ÿæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
     */
    std::chrono::milliseconds suggestDelay(const TaskInfo& task) const;

private:
    mutable std::mutex mutex_;
    std::vector<TaskInfo> recentTasks_;
    std::unordered_map<std::string, std::chrono::steady_clock::time_point> resourceLastAccess_;
};

/**
 * @brief çº¿ç¨‹æ± ç»Ÿè®¡ä¿¡æ¯
 */
struct ThreadPoolStatistics {
    size_t totalThreads = 0;
    size_t activeThreads = 0;
    size_t idleThreads = 0;
    size_t queuedTasks = 0;
    size_t completedTasks = 0;
    size_t failedTasks = 0;
    double averageTaskTime = 0.0;
    double utilizationRatio = 0.0;
    std::chrono::steady_clock::time_point lastUpdate;
    
    std::string toString() const;
};

/**
 * @brief ğŸ”§ ç»Ÿä¸€çº¿ç¨‹æ± ç®¡ç†å™¨ - æ–°æ¶æ„
 */
class UnifiedThreadPoolManager {
public:
    /**
     * @brief çº¿ç¨‹æ± é…ç½®
     */
    struct PoolConfiguration {
        size_t minThreads = 1;
        size_t maxThreads = std::thread::hardware_concurrency();
        std::chrono::seconds threadIdleTimeout{300};  // 5åˆ†é’Ÿ
        bool enableDynamicScaling = true;
        bool enableTaskPriority = true;
    };
    
    /**
     * @brief æ„é€ å‡½æ•°
     */
    explicit UnifiedThreadPoolManager(const PoolConfiguration& config = {});
    
    /**
     * @brief ææ„å‡½æ•° - ğŸ”§ æ¸è¿›å¼ä¼˜é›…å…³é—­
     */
    ~UnifiedThreadPoolManager();
    
    // ç¦ç”¨å¤åˆ¶å’Œç§»åŠ¨
    UnifiedThreadPoolManager(const UnifiedThreadPoolManager&) = delete;
    UnifiedThreadPoolManager& operator=(const UnifiedThreadPoolManager&) = delete;
    UnifiedThreadPoolManager(UnifiedThreadPoolManager&&) = delete;
    UnifiedThreadPoolManager& operator=(UnifiedThreadPoolManager&&) = delete;
    
    // === ğŸ”§ æ¨¡å¼æ§åˆ¶ ===
    
    /**
     * @brief è®¾ç½®è¿è¡Œæ¨¡å¼
     */
    enum class RunMode {
        PRODUCTION,    // ç”Ÿäº§æ¨¡å¼ï¼šå®Œæ•´å¤šçº¿ç¨‹
        TESTING,       // æµ‹è¯•æ¨¡å¼ï¼šå—æ§å¹¶å‘
        SINGLE_THREAD, // å•çº¿ç¨‹æ¨¡å¼ï¼šé¡ºåºæ‰§è¡Œ
        DEBUG          // è°ƒè¯•æ¨¡å¼ï¼šè¯¦ç»†æ—¥å¿—
    };
    
    void setRunMode(RunMode mode);
    RunMode getRunMode() const { return runMode_.load(); }
    
    // === ğŸš€ æ™ºèƒ½ä»»åŠ¡æäº¤æ¥å£ ===
    
    /**
     * @brief æäº¤æ™ºèƒ½è°ƒåº¦ä»»åŠ¡
     */
    template<typename Func>
    auto submitTask(Func&& func, 
                   TaskType taskType = TaskType::CPU_INTENSIVE,
                   TaskPriority priority = TaskPriority::NORMAL,
                   const std::vector<std::string>& resourceHints = {})
        -> boost::future<std::invoke_result_t<Func>>;
    
    /**
     * @brief æ‰¹é‡æ–‡ä»¶å¤„ç† - ğŸ”§ æ™ºèƒ½å¹¶å‘æ§åˆ¶
     */
    template<typename Func>
    auto processBatchFiles(const std::vector<std::string>& filePaths,
                          Func&& processor,
                          size_t maxConcurrency = 0)  // 0 = è‡ªåŠ¨æ£€æµ‹
        -> boost::future<std::vector<std::invoke_result_t<Func, std::string>>>;
    
    /**
     * @brief æäº¤æ–‡ä»¶å¤„ç†ä»»åŠ¡ - æ™ºèƒ½èµ„æºç®¡ç†
     */
    template<typename Func>
    auto submitFileTask(Func&& func,
                       const std::string& filePath,
                       TaskPriority priority = TaskPriority::NORMAL)
        -> boost::future<std::invoke_result_t<Func>>;
    
    // === ğŸ“Š ç›‘æ§å’Œç®¡ç† ===
    
    /**
     * @brief è·å–å®æ—¶ç»Ÿè®¡
     */
    ThreadPoolStatistics getStatistics() const;
    
    /**
     * @brief è·å–å¥åº·çŠ¶æ€
     */
    struct HealthStatus {
        bool healthy = true;
        double cpuUtilization = 0.0;
        size_t pendingTasks = 0;
        std::vector<std::string> warnings;
        std::vector<std::string> recommendations;
    };
    
    HealthStatus getHealthStatus() const;
    
    /**
     * @brief æ€§èƒ½è°ƒä¼˜å»ºè®®
     */
    std::vector<std::string> getPerformanceSuggestions() const;
    
    // === ğŸ”§ ç”Ÿå‘½å‘¨æœŸç®¡ç† ===
    
    /**
     * @brief è¯·æ±‚ä¼˜é›…å…³é—­
     */
    void requestShutdown(std::chrono::seconds timeout = std::chrono::seconds{30});
    
    /**
     * @brief æ£€æŸ¥æ˜¯å¦æ­£åœ¨å…³é—­
     */
    bool isShuttingDown() const { return shutdownRequested_.load(); }
    
    /**
     * @brief ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
     */
    bool waitForCompletion(std::chrono::seconds timeout = std::chrono::seconds{10});

private:
    // === å†…éƒ¨çŠ¶æ€ ===
    std::unique_ptr<boost::asio::thread_pool> primaryPool_;
    std::unique_ptr<boost::asio::thread_pool> ioPool_;        // ä¸“ç”¨I/Oæ± 
    std::unique_ptr<boost::asio::thread_pool> quickPool_;     // å¿«é€Ÿä»»åŠ¡æ± 
    
    std::unique_ptr<IntelligentTaskScheduler> scheduler_;
    
    PoolConfiguration config_;
    std::atomic<RunMode> runMode_{RunMode::PRODUCTION};
    
    // çŠ¶æ€æ§åˆ¶
    std::atomic<bool> shutdownRequested_{false};
    std::atomic<size_t> activeTasks_{0};
    std::atomic<size_t> completedTasks_{0};
    
    mutable std::mutex statsMutex_;
    ThreadPoolStatistics stats_;
    
    // === å†…éƒ¨æ–¹æ³• ===
    void initializePools();
    boost::asio::thread_pool& selectPool(TaskType taskType);
    void updateStatistics();
    void gracefulShutdown(std::chrono::seconds timeout);
    
    // ä»»åŠ¡æ‰§è¡ŒåŒ…è£…å™¨
    template<typename Func>
    void executeTask(Func&& func, const IntelligentTaskScheduler::TaskInfo& taskInfo);
};

// === ğŸš€ æ¨¡æ¿å®ç° ===

template<typename Func>
auto UnifiedThreadPoolManager::submitTask(Func&& func, 
                                         TaskType taskType,
                                         TaskPriority priority,
                                         const std::vector<std::string>& resourceHints)
    -> boost::future<std::invoke_result_t<Func>> {
    
    using ResultType = std::invoke_result_t<Func>;
    
    // ğŸ”§ å•çº¿ç¨‹æ¨¡å¼ï¼šç›´æ¥æ‰§è¡Œ
    if (runMode_.load() == RunMode::SINGLE_THREAD) {
        auto promise = std::make_shared<boost::promise<ResultType>>();
        auto future = promise->get_future();
        
        try {
            if constexpr (std::is_void_v<ResultType>) {
                func();
                promise->set_value();
            } else {
                promise->set_value(func());
            }
        } catch (...) {
            promise->set_exception(std::current_exception());
        }
        
        return future;
    }
    
    auto promise = std::make_shared<boost::promise<ResultType>>();
    auto future = promise->get_future();
    
    // åˆ›å»ºä»»åŠ¡ä¿¡æ¯
    IntelligentTaskScheduler::TaskInfo taskInfo;
    taskInfo.type = taskType;
    taskInfo.priority = priority;
    taskInfo.resourceHints = resourceHints;
    taskInfo.submitTime = std::chrono::steady_clock::now();
    
    // æ™ºèƒ½é€‰æ‹©çº¿ç¨‹æ± 
    auto& pool = selectPool(taskType);
    
    // å¢åŠ æ´»è·ƒä»»åŠ¡è®¡æ•°
    activeTasks_.fetch_add(1);
    
    boost::asio::post(pool, [this, promise, func = std::forward<Func>(func), taskInfo]() mutable {
        try {
            if constexpr (std::is_void_v<ResultType>) {
                func();
                promise->set_value();
            } else {
                promise->set_value(func());
            }
            
            completedTasks_.fetch_add(1);
        } catch (...) {
            promise->set_exception(std::current_exception());
        }
        
        activeTasks_.fetch_sub(1);
    });
    
    return future;
}

template<typename Func>
auto UnifiedThreadPoolManager::submitFileTask(Func&& func,
                                             const std::string& filePath,
                                             TaskPriority priority)
    -> boost::future<std::invoke_result_t<Func>> {
    
    // æ–‡ä»¶ä»»åŠ¡é€šå¸¸æ˜¯I/Oå¯†é›†å‹ï¼Œæä¾›æ–‡ä»¶è·¯å¾„ä½œä¸ºèµ„æºæç¤º
    return submitTask(std::forward<Func>(func), 
                     TaskType::IO_BOUND, 
                     priority, 
                     {filePath});
}

template<typename Func>
auto UnifiedThreadPoolManager::processBatchFiles(const std::vector<std::string>& filePaths,
                                                 Func&& processor,
                                                 size_t maxConcurrency)
    -> boost::future<std::vector<std::invoke_result_t<Func, std::string>>> {
    
    using ResultType = std::invoke_result_t<Func, std::string>;
    
    auto promise = std::make_shared<boost::promise<std::vector<ResultType>>>();
    auto future = promise->get_future();
    
    // ğŸ”§ æ™ºèƒ½å¹¶å‘æ§åˆ¶
    if (maxConcurrency == 0) {
        // è‡ªåŠ¨æ£€æµ‹ï¼šæ ¹æ®æ–‡ä»¶æ•°é‡å’Œç³»ç»Ÿèµ„æºå†³å®šå¹¶å‘åº¦
        maxConcurrency = std::min(filePaths.size(), 
                                 static_cast<size_t>(std::thread::hardware_concurrency()));
    }
    
    // ğŸ”§ å•çº¿ç¨‹æ¨¡å¼ï¼šé¡ºåºå¤„ç†
    if (runMode_.load() == RunMode::SINGLE_THREAD) {
        try {
            std::vector<ResultType> results;
            results.reserve(filePaths.size());
            
            for (const auto& filePath : filePaths) {
                if constexpr (std::is_void_v<ResultType>) {
                    processor(filePath);
                } else {
                    results.push_back(processor(filePath));
                }
            }
            
            if constexpr (std::is_void_v<ResultType>) {
                promise->set_value(std::vector<ResultType>{});
            } else {
                promise->set_value(std::move(results));
            }
        } catch (...) {
            promise->set_exception(std::current_exception());
        }
        
        return future;
    }
    
    // ğŸš€ å¤šçº¿ç¨‹æ¨¡å¼ï¼šæ™ºèƒ½æ‰¹å¤„ç†
    // ä½¿ç”¨æ¡ä»¶å˜é‡å’Œè®¡æ•°å™¨æ§åˆ¶å¹¶å‘åº¦ï¼Œå…¼å®¹C++17
    auto activeCount = std::make_shared<std::atomic<size_t>>(0);
    auto maxConcur = std::make_shared<size_t>(maxConcurrency);
    auto concurrencyMutex = std::make_shared<std::mutex>();
    auto concurrencyCV = std::make_shared<std::condition_variable>();
    
    auto results = std::make_shared<std::vector<ResultType>>(filePaths.size());
    auto completed = std::make_shared<std::atomic<size_t>>(0);
    auto hasError = std::make_shared<std::atomic<bool>>(false);
    auto errorPtr = std::make_shared<std::exception_ptr>();
    
    for (size_t i = 0; i < filePaths.size(); ++i) {
        submitTask([=, processor = std::forward<Func>(processor)]() {
            // ç­‰å¾…å¹¶å‘æ§åˆ¶
            {
                std::unique_lock<std::mutex> lock(*concurrencyMutex);
                concurrencyCV->wait(lock, [=]() { 
                    return activeCount->load() < *maxConcur; 
                });
                activeCount->fetch_add(1);
            }
            
            try {
                if (!hasError->load()) {
                    if constexpr (std::is_void_v<ResultType>) {
                        processor(filePaths[i]);
                    } else {
                        (*results)[i] = processor(filePaths[i]);
                    }
                }
            } catch (...) {
                hasError->store(true);
                *errorPtr = std::current_exception();
            }
            
            // é‡Šæ”¾å¹¶å‘æ§åˆ¶
            {
                std::lock_guard<std::mutex> lock(*concurrencyMutex);
                activeCount->fetch_sub(1);
            }
            concurrencyCV->notify_one();
            
            // æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if (completed->fetch_add(1) + 1 == filePaths.size()) {
                if (hasError->load()) {
                    promise->set_exception(*errorPtr);
                } else {
                    if constexpr (std::is_void_v<ResultType>) {
                        promise->set_value(std::vector<ResultType>{});
                    } else {
                        promise->set_value(*results);
                    }
                }
            }
        }, TaskType::IO_BOUND, TaskPriority::NORMAL, {filePaths[i]});
    }
    
    return future;
}

} // namespace oscean::common_utils::infrastructure 