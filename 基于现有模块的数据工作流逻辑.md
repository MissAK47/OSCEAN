# 基于现有模块的数据处理工作流逻辑

## 整体流程图
```
用户查询请求 → 查询组装 → 数据读取 → 处理流水线 → 格式化输出
     ↓           ↓         ↓         ↓          ↓
  QueryBuilder → MetadataService → DataAccessService → ProcessingPipeline → OutputService
```

## 1. 输入接口设计

### 核心查询参数
```cpp
struct DataQueryRequest {
    // 时间条件
    std::optional<std::chrono::system_clock::time_point> startTime;
    std::optional<std::chrono::system_clock::time_point> endTime;
    
    // 空间条件 (WGS84坐标)
    std::optional<BoundingBox> spatialBounds;    // 面
    std::optional<Point> queryPoint;             // 点  
    std::optional<LineString> queryLine;         // 线
    std::optional<Polygon> queryPolygon;         // 面
    
    // 垂直条件
    std::optional<double> minDepth;
    std::optional<double> maxDepth;
    std::vector<int> specificLayers;             // 指定层数
    
    // 数据类型条件
    std::vector<std::string> variableNames;      // 如 ["temperature", "salinity"]
    std::optional<std::string> datasetType;      // 如 "satellite", "model"
    
    // 输出控制
    OutputFormat outputFormat = OutputFormat::NetCDF;  // nc/txt/csv/tiff
    std::optional<int> maxFileSize_MB;           // 文件分块大小
    
    // 插值控制
    bool enableInterpolation = false;
    std::optional<double> targetSpatialResolution;     // 米为单位
    std::optional<std::chrono::minutes> targetTimeResolution;
};
```

## 2. 数据流逻辑

### 步骤1：查询组装 (QueryBuilder)
**功能**: 将用户请求转换为标准查询条件
**现有模块**: 新建轻量级QueryBuilder
```cpp
// 使用现有metadata_service的查询能力
auto query = QueryBuilder::fromRequest(request);
auto datasets = metadataService->queryMetadataAsync(query).get();
```

### 步骤2：数据发现 (MetadataService)
**功能**: 根据条件查找匹配的数据集
**现有模块**: `metadata_service::QueryEngine`
```cpp
// 已有功能，直接调用
std::vector<MetadataEntry> datasets = metadataService->queryMetadataAsync(query).get();
```

### 步骤3：数据读取 (DataAccessService)
**功能**: 从文件系统读取实际数据
**现有模块**: `data_access_service` NetCDF/GDAL读取器
```cpp
// 已有功能，针对每个数据集
for(const auto& dataset : datasets) {
    auto reader = dataAccessService->createReader(dataset.filePath);
    
    // 根据查询类型读取
    if(request.queryPoint) {
        data = reader->readPointData(*request.queryPoint, variableNames);
    } else if(request.spatialBounds) {
        data = reader->readGridData(*request.spatialBounds, variableNames);
    }
    // ... 其他几何类型
}
```

### 步骤4：数据处理流水线 (ProcessingPipeline)
**功能**: 坐标转换、空间处理、插值
**现有模块**: 组合调用 `crs_service`, `spatial_ops_service`, `interpolation_service`

```cpp
class ProcessingPipeline {
public:
    ProcessedData process(const RawData& data, const DataQueryRequest& request) {
        ProcessedData result = data;
        
        // 4.1 坐标转换 (如果需要)
        if(needsCoordinateTransform(data, request)) {
            result = transformCoordinates(result);
        }
        
        // 4.2 空间处理 (裁剪、几何操作)
        if(request.spatialBounds || request.queryPolygon) {
            result = applySpatialFilter(result, request);
        }
        
        // 4.3 插值处理 (如果需要)
        if(request.enableInterpolation) {
            result = applyInterpolation(result, request);
        }
        
        return result;
    }

private:
    // 使用现有crs_service
    ProcessedData transformCoordinates(const ProcessedData& data) {
        return crsService->transformCoordinates(data, targetCRS);
    }
    
    // 使用现有spatial_ops_service
    ProcessedData applySpatialFilter(const ProcessedData& data, const DataQueryRequest& request) {
        return spatialOpsService->clip(data, request.spatialBounds);
    }
    
    // 使用现有interpolation_service  
    ProcessedData applyInterpolation(const ProcessedData& data, const DataQueryRequest& request) {
        if(request.targetSpatialResolution) {
            return interpolationService->resample(data, *request.targetSpatialResolution);
        }
        return data;
    }
};
```

### 步骤5：格式化输出 (OutputService)
**功能**: 将处理后的数据转换为指定格式
**现有模块**: `output_generation` (需要扩展)

```cpp
class OutputService {
public:
    std::vector<std::string> generateOutput(const ProcessedData& data, const DataQueryRequest& request) {
        switch(request.outputFormat) {
            case OutputFormat::NetCDF:
                return generateNetCDF(data, request.maxFileSize_MB);
            case OutputFormat::CSV:
                return generateCSV(data, request.maxFileSize_MB);
            case OutputFormat::GeoTIFF:
                return generateGeoTIFF(data, request.maxFileSize_MB);
            // ... 其他格式
        }
    }

private:
    // 利用现有的tile_service基础，扩展支持更多格式
    std::vector<std::string> generateNetCDF(const ProcessedData& data, std::optional<int> maxSizeMB);
    std::vector<std::string> generateCSV(const ProcessedData& data, std::optional<int> maxSizeMB);
    // ...
};
```

## 3. 主工作流实现

```cpp
class DataProcessingWorkflow {
public:
    DataProcessingWorkflow(
        std::shared_ptr<MetadataService> metadataService,
        std::shared_ptr<DataAccessService> dataAccessService,
        std::shared_ptr<CrsService> crsService,
        std::shared_ptr<SpatialOpsService> spatialOpsService,
        std::shared_ptr<InterpolationService> interpolationService,
        std::shared_ptr<OutputService> outputService
    ) : metadataService_(metadataService),
        dataAccessService_(dataAccessService),
        processingPipeline_(crsService, spatialOpsService, interpolationService),
        outputService_(outputService) {}

    boost::future<WorkflowResult> execute(const DataQueryRequest& request) {
        return boost::async(boost::launch::async, [this, request]() {
            try {
                // 步骤1-2: 查询数据集
                auto query = QueryBuilder::fromRequest(request);
                auto datasets = metadataService_->queryMetadataAsync(query).get();
                
                if(datasets.empty()) {
                    return WorkflowResult::noDataFound();
                }
                
                // 步骤3: 读取数据
                auto rawData = readDataFromSources(datasets, request);
                
                // 步骤4: 处理数据
                auto processedData = processingPipeline_.process(rawData, request);
                
                // 步骤5: 生成输出
                auto outputFiles = outputService_->generateOutput(processedData, request);
                
                return WorkflowResult::success(outputFiles);
                
            } catch(const std::exception& e) {
                return WorkflowResult::failure(e.what());
            }
        });
    }

private:
    std::shared_ptr<MetadataService> metadataService_;
    std::shared_ptr<DataAccessService> dataAccessService_;
    ProcessingPipeline processingPipeline_;
    std::shared_ptr<OutputService> outputService_;
    
    RawData readDataFromSources(const std::vector<MetadataEntry>& datasets, 
                               const DataQueryRequest& request) {
        // 使用现有data_access_service读取数据
        // 根据查询几何类型选择合适的读取方法
    }
};
```

## 4. 功能扩展需求

### 4.1 需要扩展的功能

1. **QueryBuilder** - 新建轻量级查询组装器
2. **OutputService扩展** - 基于现有tile_service扩展多格式输出
3. **ProcessingPipeline** - 新建编排层，调用现有服务

### 4.2 优化建议

**在功能模块中优化**:
- 各个服务内部的性能优化 (如缓存、并行读取)
- 数据结构优化

**在工作流层优化**:
- 并行处理多个数据集
- 智能缓存中间结果
- 流式处理大数据

## 5. 关键点总结

✅ **正确做法**:
- 工作流作为编排层，调用现有服务
- 每个步骤职责单一、接口清晰
- 利用现有模块的成熟功能

❌ **避免问题**:
- 不在工作流中重新实现已有功能
- 不过度设计复杂的抽象层
- 不忽略现有模块的能力 