/**
 * @file cache_strategies.h
 * @brief å†…éƒ¨ç¼“å­˜ç­–ç•¥å®ç° - ä»…ä¾›å†…éƒ¨ä½¿ç”¨ï¼Œå¤–éƒ¨è¯·ä½¿ç”¨CommonServicesFactory
 * @author OSCEAN Team
 * @date 2024
 * 
 * âš ï¸  é‡è¦æç¤ºï¼š
 * è¿™æ˜¯å†…éƒ¨å®ç°æ–‡ä»¶ï¼Œå¤–éƒ¨ä»£ç ä¸åº”ç›´æ¥ä½¿ç”¨ï¼
 * 
 * å¤–éƒ¨ä»£ç åº”è¯¥ä½¿ç”¨CommonServicesFactoryçš„ç»Ÿä¸€æ¥å£ï¼š
 * #include "common_utils/infrastructure/common_services_factory.h"
 * 
 * auto factory = CommonServicesFactory::create();
 * auto lruCache = factory->createCache<K,V>("cache1", 1000, "LRU");
 * auto ttlCache = factory->createCache<K,V>("cache2", 500, "TTL");
 * 
 * æ”¯æŒçš„ç­–ç•¥ï¼šLRU, LFU, TTL, FIFO, Adaptive
 */

#pragma once

// å¼•ç”¨ç»Ÿä¸€çš„boosté…ç½® - å¿…é¡»åœ¨æœ€å‰é¢
#include "common_utils/utilities/boost_config.h"
#include <boost/thread/future.hpp>
#include <boost/asio/thread_pool.hpp>
#include <boost/asio/post.hpp>

#include "icache_manager.h"
#include "cache_config.h"
#include <unordered_map>
#include <list>
#include <chrono>
#include <mutex>
#include <shared_mutex>
#include <algorithm>
#include <atomic>
#include <queue>
#include <map>
#include <memory>

namespace oscean::common_utils::cache {

/**
 * @brief LRUç¼“å­˜ç­–ç•¥å®ç° - æ”¯æŒboost::futureå¼‚æ­¥æ“ä½œ
 * 
 * ä½¿ç”¨åŒå‘é“¾è¡¨+å“ˆå¸Œè¡¨å®ç°O(1)çš„æ’å…¥ã€åˆ é™¤ã€è®¿é—®æ“ä½œ
 * å…¨é¢æ”¯æŒå¼‚æ­¥æ“ä½œï¼Œç¬¦åˆOSCEANé¡¹ç›®æ¶æ„æ ‡å‡†
 */
template<typename Key, typename Value>
class LRUCacheStrategy : public ICacheManager<Key, Value> {
private:
    struct Node {
        Key key;
        Value value;
        std::chrono::steady_clock::time_point accessTime;
        std::chrono::steady_clock::time_point insertTime;
        std::shared_ptr<Node> prev;
        std::shared_ptr<Node> next;
        
        Node(const Key& k, const Value& v) 
            : key(k), value(v)
            , accessTime(std::chrono::steady_clock::now())
            , insertTime(std::chrono::steady_clock::now()) {}
    };
    
    using NodePtr = std::shared_ptr<Node>;
    
    std::unordered_map<Key, NodePtr> hashTable_;
    NodePtr head_;
    NodePtr tail_;
    size_t capacity_;
    mutable std::shared_mutex rwMutex_;
    std::shared_ptr<boost::asio::thread_pool> threadPool_;
    
    // ç»Ÿè®¡ä¿¡æ¯
    mutable std::atomic<size_t> hitCount_{0};
    mutable std::atomic<size_t> missCount_{0};
    mutable std::atomic<size_t> evictionCount_{0};
    std::chrono::steady_clock::time_point creationTime_;

public:
    explicit LRUCacheStrategy(size_t capacity = 1000, 
                            std::shared_ptr<boost::asio::thread_pool> threadPool = nullptr);
    
    // === åŒæ­¥æ¥å£å®ç° ===
    
    std::optional<Value> get(const Key& key) override;
    bool put(const Key& key, const Value& value) override;
    bool remove(const Key& key) override;
    bool containsKey(const Key& key) const override;
    void clear() override;
    size_t size() const override;
    
    // === ğŸ”´ è¡¥å……ç¼ºå¤±çš„ICacheManageræ¥å£æ–¹æ³•å£°æ˜ ===
    bool contains(const Key& key) const override;
    void putBatch(const std::map<Key, Value>& items) override;
    std::map<Key, Value> getBatch(const std::vector<Key>& keys) override;
    void removeBatch(const std::vector<Key>& keys) override;
    size_t capacity() const override;
    void setCapacity(size_t newCapacity) override;
    void evictExpired() override;
    void optimize() override;
    CacheStatistics getStatistics() const override;
    void resetStatistics() override;
    std::string generateReport() const override;
    void updateConfig(const CacheConfig& config) override;
    CacheConfig getConfig() const override;
    CacheStrategy getStrategy() const override;
    
    // === å¼‚æ­¥æ¥å£å®ç° ===
    
    boost::future<std::optional<Value>> getAsync(const Key& key) override;
    boost::future<bool> putAsync(const Key& key, const Value& value) override;
    boost::future<bool> removeAsync(const Key& key) override;
    
    boost::future<std::vector<std::pair<Key, std::optional<Value>>>> 
    getBatchAsync(const std::vector<Key>& keys) override;
    
    boost::future<std::vector<bool>> 
    putBatchAsync(const std::vector<std::pair<Key, Value>>& items) override;
    
    boost::future<CacheStatistics> getStatisticsAsync() override;
    boost::future<void> clearAsync() override;
    
    boost::future<size_t> 
    warmupAsync(const std::vector<std::pair<Key, Value>>& warmupData) override;
    
    boost::future<std::optional<Value>> 
    refreshAsync(const Key& key, std::function<boost::future<Value>()> provider) override;
    
    boost::future<Value> 
    computeIfAbsentAsync(const Key& key, std::function<boost::future<Value>()> computer) override;
    
    // === LRUä¸“ç”¨æ–¹æ³• ===
    
    /**
     * @brief å¼‚æ­¥è·å–æœ€è¿‘è®¿é—®çš„Nä¸ªé¡¹ç›®
     */
    boost::future<std::vector<std::pair<Key, Value>>> getMostRecentAsync(size_t count);
    
    /**
     * @brief å¼‚æ­¥è·å–æœ€å°‘è®¿é—®çš„Nä¸ªé¡¹ç›®
     */
    boost::future<std::vector<std::pair<Key, Value>>> getLeastRecentAsync(size_t count);
    
    /**
     * @brief å¼‚æ­¥ä¼˜åŒ–ç¼“å­˜ - æ¸…ç†è¿‡æœŸé¡¹ç›®
     */
    boost::future<size_t> optimizeAsync();

private:
    void moveToFront(NodePtr node);
    void removeNode(NodePtr node);
    void addToFront(NodePtr node);
    NodePtr removeTail();
    void initializeList();
    
    // å¼‚æ­¥è¾…åŠ©æ–¹æ³•
    template<typename Func>
    auto executeAsync(Func&& func) -> boost::future<decltype(func())>;
};

/**
 * @brief LFUç¼“å­˜ç­–ç•¥å®ç° - æ”¯æŒboost::futureå¼‚æ­¥æ“ä½œ
 * 
 * åŸºäºè®¿é—®é¢‘ç‡çš„ç¼“å­˜æ·˜æ±°ç­–ç•¥ï¼Œæ”¯æŒå¼‚æ­¥æ“ä½œ
 */
template<typename Key, typename Value>
class LFUCacheStrategy : public ICacheManager<Key, Value> {
private:
    struct LFUNode {
        Key key;
        Value value;
        size_t frequency;
        std::chrono::steady_clock::time_point lastAccess;
        
        // é»˜è®¤æ„é€ å‡½æ•°
        LFUNode() = default;
        
        LFUNode(const Key& k, const Value& v) 
            : key(k), value(v), frequency(1)
            , lastAccess(std::chrono::steady_clock::now()) {}
    };
    
    std::unordered_map<Key, LFUNode> cache_;
    std::unordered_map<size_t, std::list<Key>> frequencyLists_;
    std::unordered_map<Key, typename std::list<Key>::iterator> keyToIterator_;
    size_t capacity_;
    size_t minFrequency_;
    mutable std::shared_mutex rwMutex_;
    std::shared_ptr<boost::asio::thread_pool> threadPool_;
    
    // ç»Ÿè®¡ä¿¡æ¯
    mutable std::atomic<size_t> hitCount_{0};
    mutable std::atomic<size_t> missCount_{0};
    mutable std::atomic<size_t> evictionCount_{0};

public:
    explicit LFUCacheStrategy(size_t capacity = 1000,
                            std::shared_ptr<boost::asio::thread_pool> threadPool = nullptr);
    
    // === åŒæ­¥æ¥å£å®ç° ===
    std::optional<Value> get(const Key& key) override;
    bool put(const Key& key, const Value& value) override;
    bool remove(const Key& key) override;
    bool containsKey(const Key& key) const override;
    void clear() override;
    size_t size() const override;
    
    // === è¡¥å……ç¼ºå¤±çš„ICacheManageræ¥å£æ–¹æ³• ===
    bool contains(const Key& key) const override;
    void putBatch(const std::map<Key, Value>& items) override;
    std::map<Key, Value> getBatch(const std::vector<Key>& keys) override;
    void removeBatch(const std::vector<Key>& keys) override;
    size_t capacity() const override;
    void setCapacity(size_t newCapacity) override;
    void evictExpired() override;
    void optimize() override;
    CacheStatistics getStatistics() const override;
    void resetStatistics() override;
    std::string generateReport() const override;
    void updateConfig(const CacheConfig& config) override;
    CacheConfig getConfig() const override;
    CacheStrategy getStrategy() const override;
    
    // === å¼‚æ­¥æ¥å£å®ç° ===
    boost::future<std::optional<Value>> getAsync(const Key& key) override;
    boost::future<bool> putAsync(const Key& key, const Value& value) override;
    boost::future<bool> removeAsync(const Key& key) override;
    
    boost::future<std::vector<std::pair<Key, std::optional<Value>>>> 
    getBatchAsync(const std::vector<Key>& keys) override;
    
    boost::future<std::vector<bool>> 
    putBatchAsync(const std::vector<std::pair<Key, Value>>& items) override;
    
    boost::future<CacheStatistics> getStatisticsAsync() override;
    boost::future<void> clearAsync() override;
    
    boost::future<size_t> 
    warmupAsync(const std::vector<std::pair<Key, Value>>& warmupData) override;
    
    boost::future<std::optional<Value>> 
    refreshAsync(const Key& key, std::function<boost::future<Value>()> provider) override;
    
    boost::future<Value> 
    computeIfAbsentAsync(const Key& key, std::function<boost::future<Value>()> computer) override;

private:
    void updateFrequency(const Key& key);
    void evictLFU();
    
    template<typename Func>
    auto executeAsync(Func&& func) -> boost::future<decltype(func())>;
};

/**
 * @brief FIFOç¼“å­˜ç­–ç•¥å®ç° - æ”¯æŒboost::futureå¼‚æ­¥æ“ä½œ
 */
template<typename Key, typename Value>
class FIFOCacheStrategy : public ICacheManager<Key, Value> {
private:
    std::unordered_map<Key, Value> cache_;
    std::queue<Key> insertionOrder_;
    size_t capacity_;
    mutable std::shared_mutex rwMutex_;
    std::shared_ptr<boost::asio::thread_pool> threadPool_;
    
    // ç»Ÿè®¡ä¿¡æ¯
    mutable std::atomic<size_t> hitCount_{0};
    mutable std::atomic<size_t> missCount_{0};
    mutable std::atomic<size_t> evictionCount_{0};

public:
    explicit FIFOCacheStrategy(size_t capacity = 1000,
                             std::shared_ptr<boost::asio::thread_pool> threadPool = nullptr);
    
    // === åŒæ­¥æ¥å£å®ç° ===
    std::optional<Value> get(const Key& key) override;
    bool put(const Key& key, const Value& value) override;
    bool remove(const Key& key) override;
    bool containsKey(const Key& key) const override;
    void clear() override;
    size_t size() const override;
    
    // === è¡¥å……ç¼ºå¤±çš„ICacheManageræ¥å£æ–¹æ³• ===
    bool contains(const Key& key) const override;
    void putBatch(const std::map<Key, Value>& items) override;
    std::map<Key, Value> getBatch(const std::vector<Key>& keys) override;
    void removeBatch(const std::vector<Key>& keys) override;
    size_t capacity() const override;
    void setCapacity(size_t newCapacity) override;
    void evictExpired() override;
    void optimize() override;
    CacheStatistics getStatistics() const override;
    void resetStatistics() override;
    std::string generateReport() const override;
    void updateConfig(const CacheConfig& config) override;
    CacheConfig getConfig() const override;
    CacheStrategy getStrategy() const override;
    
    // === å¼‚æ­¥æ¥å£å®ç° ===
    boost::future<std::optional<Value>> getAsync(const Key& key) override;
    boost::future<bool> putAsync(const Key& key, const Value& value) override;
    boost::future<bool> removeAsync(const Key& key) override;
    
    boost::future<std::vector<std::pair<Key, std::optional<Value>>>> 
    getBatchAsync(const std::vector<Key>& keys) override;
    
    boost::future<std::vector<bool>> 
    putBatchAsync(const std::vector<std::pair<Key, Value>>& items) override;
    
    boost::future<CacheStatistics> getStatisticsAsync() override;
    boost::future<void> clearAsync() override;
    
    boost::future<size_t> 
    warmupAsync(const std::vector<std::pair<Key, Value>>& warmupData) override;
    
    boost::future<std::optional<Value>> 
    refreshAsync(const Key& key, std::function<boost::future<Value>()> provider) override;
    
    boost::future<Value> 
    computeIfAbsentAsync(const Key& key, std::function<boost::future<Value>()> computer) override;

private:
    template<typename Func>
    auto executeAsync(Func&& func) -> boost::future<decltype(func())>;
};

/**
 * @brief TTLç¼“å­˜ç­–ç•¥å®ç° - æ”¯æŒboost::futureå¼‚æ­¥æ“ä½œ
 * 
 * åŸºäºç”Ÿå­˜æ—¶é—´çš„ç¼“å­˜ç­–ç•¥ï¼Œæ”¯æŒè‡ªåŠ¨è¿‡æœŸå’Œå¼‚æ­¥æ¸…ç†
 */
template<typename Key, typename Value>
class TTLCacheStrategy : public ICacheManager<Key, Value> {
private:
    struct TTLNode {
        Value value;
        std::chrono::steady_clock::time_point expiryTime;
        
        TTLNode(const Value& v, std::chrono::seconds ttl)
            : value(v), expiryTime(std::chrono::steady_clock::now() + ttl) {}
        
        bool isExpired() const {
            return std::chrono::steady_clock::now() >= expiryTime;
        }
    };
    
    std::unordered_map<Key, TTLNode> cache_;
    std::chrono::seconds defaultTTL_;
    mutable std::shared_mutex rwMutex_;
    std::shared_ptr<boost::asio::thread_pool> threadPool_;
    
    // è‡ªåŠ¨æ¸…ç†
    std::atomic<bool> autoCleanupEnabled_{true};
    std::chrono::seconds cleanupInterval_{60};
    boost::future<void> cleanupTask_;
    
    // ç»Ÿè®¡ä¿¡æ¯
    mutable std::atomic<size_t> hitCount_{0};
    mutable std::atomic<size_t> missCount_{0};
    mutable std::atomic<size_t> expirationCount_{0};

public:
    explicit TTLCacheStrategy(std::chrono::seconds defaultTTL = std::chrono::minutes(30),
                            std::shared_ptr<boost::asio::thread_pool> threadPool = nullptr);
    
    ~TTLCacheStrategy();
    
    // === åŒæ­¥æ¥å£å®ç° ===
    std::optional<Value> get(const Key& key) override;
    bool put(const Key& key, const Value& value) override;
    bool remove(const Key& key) override;
    bool containsKey(const Key& key) const override;
    void clear() override;
    size_t size() const override;
    
    // === ğŸ”´ è¡¥å……ç¼ºå¤±çš„ICacheManageræ¥å£æ–¹æ³•å£°æ˜ ===
    bool contains(const Key& key) const override;
    void putBatch(const std::map<Key, Value>& items) override;
    std::map<Key, Value> getBatch(const std::vector<Key>& keys) override;
    void removeBatch(const std::vector<Key>& keys) override;
    size_t capacity() const override;
    void setCapacity(size_t newCapacity) override;
    void evictExpired() override;
    void optimize() override;
    CacheStatistics getStatistics() const override;
    void resetStatistics() override;
    std::string generateReport() const override;
    void updateConfig(const CacheConfig& config) override;
    CacheConfig getConfig() const override;
    CacheStrategy getStrategy() const override;
    
    // === å¼‚æ­¥æ¥å£å®ç° ===
    boost::future<std::optional<Value>> getAsync(const Key& key) override;
    boost::future<bool> putAsync(const Key& key, const Value& value) override;
    boost::future<bool> removeAsync(const Key& key) override;
    
    boost::future<std::vector<std::pair<Key, std::optional<Value>>>> 
    getBatchAsync(const std::vector<Key>& keys) override;
    
    boost::future<std::vector<bool>> 
    putBatchAsync(const std::vector<std::pair<Key, Value>>& items) override;
    
    boost::future<CacheStatistics> getStatisticsAsync() override;
    boost::future<void> clearAsync() override;
    
    boost::future<size_t> 
    warmupAsync(const std::vector<std::pair<Key, Value>>& warmupData) override;
    
    boost::future<std::optional<Value>> 
    refreshAsync(const Key& key, std::function<boost::future<Value>()> provider) override;
    
    boost::future<Value> 
    computeIfAbsentAsync(const Key& key, std::function<boost::future<Value>()> computer) override;
    
    // === TTLä¸“ç”¨æ–¹æ³• ===
    
    /**
     * @brief è®¾ç½®é¡¹ç›®çš„è‡ªå®šä¹‰TTL
     */
    bool putWithTTL(const Key& key, const Value& value, std::chrono::seconds ttl);
    
    /**
     * @brief å¼‚æ­¥è®¾ç½®é¡¹ç›®çš„è‡ªå®šä¹‰TTL
     */
    boost::future<bool> putWithTTLAsync(const Key& key, const Value& value, std::chrono::seconds ttl);
    
    /**
     * @brief å¼‚æ­¥æ¸…ç†è¿‡æœŸé¡¹ç›®
     * @return boost::future<size_t> æ¸…ç†çš„é¡¹ç›®æ•°
     */
    boost::future<size_t> cleanupExpiredAsync();
    
    /**
     * @brief å¼‚æ­¥è·å–å³å°†è¿‡æœŸçš„é¡¹ç›®
     */
    boost::future<std::vector<Key>> getExpiringKeysAsync(std::chrono::seconds withinTime);

private:
    void startAutoCleanup();
    void stopAutoCleanup();
    void cleanupExpiredItems();
    
    template<typename Func>
    auto executeAsync(Func&& func) -> boost::future<decltype(func())>;
};

/**
 * @brief è‡ªé€‚åº”ç¼“å­˜ç­–ç•¥ - æ”¯æŒboost::futureå¼‚æ­¥æ“ä½œ
 * 
 * æ ¹æ®è®¿é—®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç¼“å­˜ç­–ç•¥ï¼Œæ”¯æŒåŠ¨æ€åˆ‡æ¢
 */
template<typename Key, typename Value>
class AdaptiveCacheStrategy : public ICacheManager<Key, Value> {
private:
    enum class ActiveStrategy {
        LRU,
        LFU,
        FIFO,
        TTL
    };
    
    std::unique_ptr<ICacheManager<Key, Value>> currentCache_;
    ActiveStrategy currentStrategy_;
    
    // æ€§èƒ½ç›‘æ§
    std::chrono::steady_clock::time_point lastEvaluation_;
    std::chrono::seconds evaluationInterval_{300}; // 5åˆ†é’Ÿè¯„ä¼°ä¸€æ¬¡
    
    struct PerformanceMetrics {
        size_t hits = 0;
        size_t misses = 0;
        
        double hitRatio = 0.0;
        double averageAccessTime = 0.0;
        size_t evictionRate = 0;
        std::chrono::steady_clock::time_point measurementStart;
    };
    
    std::map<ActiveStrategy, PerformanceMetrics> strategyMetrics_;
    mutable std::mutex strategyMutex_;
    std::shared_ptr<boost::asio::thread_pool> threadPool_;
    
    // è‡ªåŠ¨ä¼˜åŒ–
    boost::future<void> optimizationTask_;
    std::atomic<bool> optimizationEnabled_{true};

public:
    explicit AdaptiveCacheStrategy(size_t capacity = 1000,
                                 std::shared_ptr<boost::asio::thread_pool> threadPool = nullptr);
    
    ~AdaptiveCacheStrategy();
    
    // === åŒæ­¥æ¥å£å®ç° ===
    std::optional<Value> get(const Key& key) override;
    bool put(const Key& key, const Value& value) override;
    bool remove(const Key& key) override;
    bool containsKey(const Key& key) const override;
    void clear() override;
    size_t size() const override;
    
    // === ğŸ”´ è¡¥å……ç¼ºå¤±çš„ICacheManageræ¥å£æ–¹æ³•å£°æ˜ ===
    bool contains(const Key& key) const override;
    void putBatch(const std::map<Key, Value>& items) override;
    std::map<Key, Value> getBatch(const std::vector<Key>& keys) override;
    void removeBatch(const std::vector<Key>& keys) override;
    size_t capacity() const override;
    void setCapacity(size_t newCapacity) override;
    void evictExpired() override;
    void optimize() override;
    CacheStatistics getStatistics() const override;
    void resetStatistics() override;
    std::string generateReport() const override;
    void updateConfig(const CacheConfig& config) override;
    CacheConfig getConfig() const override;
    CacheStrategy getStrategy() const override;
    
    // === å¼‚æ­¥æ¥å£å®ç° ===
    boost::future<std::optional<Value>> getAsync(const Key& key) override;
    boost::future<bool> putAsync(const Key& key, const Value& value) override;
    boost::future<bool> removeAsync(const Key& key) override;
    
    boost::future<std::vector<std::pair<Key, std::optional<Value>>>> 
    getBatchAsync(const std::vector<Key>& keys) override;
    
    boost::future<std::vector<bool>> 
    putBatchAsync(const std::vector<std::pair<Key, Value>>& items) override;
    
    boost::future<CacheStatistics> getStatisticsAsync() override;
    boost::future<void> clearAsync() override;
    
    boost::future<size_t> 
    warmupAsync(const std::vector<std::pair<Key, Value>>& warmupData) override;
    
    boost::future<std::optional<Value>> 
    refreshAsync(const Key& key, std::function<boost::future<Value>()> provider) override;
    
    boost::future<Value> 
    computeIfAbsentAsync(const Key& key, std::function<boost::future<Value>()> computer) override;
    
    // === è‡ªé€‚åº”ä¸“ç”¨æ–¹æ³• ===
    
    /**
     * @brief å¼‚æ­¥å¼ºåˆ¶ç­–ç•¥è¯„ä¼°å’Œåˆ‡æ¢
     */
    boost::future<ActiveStrategy> evaluateAndSwitchAsync();
    
    /**
     * @brief å¼‚æ­¥è·å–å½“å‰ç­–ç•¥æ€§èƒ½æŠ¥å‘Š
     */
    boost::future<std::map<std::string, double>> getPerformanceReportAsync();
    
    /**
     * @brief æ‰‹åŠ¨è®¾ç½®ç­–ç•¥
     */
    boost::future<bool> setStrategyAsync(ActiveStrategy strategy);

private:
    void startOptimizationTask();
    void stopOptimizationTask();
    ActiveStrategy selectBestStrategy();
    std::unique_ptr<ICacheManager<Key, Value>> createStrategyCache(ActiveStrategy strategy, size_t capacity);
    void migrateCacheData(ICacheManager<Key, Value>* from, ICacheManager<Key, Value>* to);
    
    template<typename Func>
    auto executeAsync(Func&& func) -> boost::future<decltype(func())>;
};

// === å·¥å‚å‡½æ•° ===

/**
 * @brief åˆ›å»ºå¼‚æ­¥LRUç¼“å­˜
 */
template<typename Key, typename Value>
boost::future<std::unique_ptr<LRUCacheStrategy<Key, Value>>> 
createLRUCacheAsync(size_t capacity, std::shared_ptr<boost::asio::thread_pool> threadPool = nullptr);

/**
 * @brief åˆ›å»ºå¼‚æ­¥LFUç¼“å­˜
 */
template<typename Key, typename Value>
boost::future<std::unique_ptr<LFUCacheStrategy<Key, Value>>> 
createLFUCacheAsync(size_t capacity, std::shared_ptr<boost::asio::thread_pool> threadPool = nullptr);

/**
 * @brief åˆ›å»ºå¼‚æ­¥è‡ªé€‚åº”ç¼“å­˜
 */
template<typename Key, typename Value>
boost::future<std::unique_ptr<AdaptiveCacheStrategy<Key, Value>>> 
createAdaptiveCacheAsync(size_t capacity, std::shared_ptr<boost::asio::thread_pool> threadPool = nullptr);

} // namespace oscean::common_utils::cache 