/**
 * @file adaptive_memory_usage_example.cpp
 * @brief è‡ªé€‚åº”å†…å­˜ç­–ç•¥ä½¿ç”¨ç¤ºä¾‹ - å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½ä¼˜åŒ–
 * 
 * æ­¤ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•åœ¨ä»¥ä¸‹åœºæ™¯ä¸­ä½¿ç”¨åŠ¨æ€å†…å­˜ç­–ç•¥ï¼š
 * 1. å¤§æ–‡ä»¶è¯»å–ï¼ˆGBçº§NetCDF/GDALæ•°æ®ï¼‰
 * 2. æ’å€¼è®¡ç®—ï¼ˆPCHIP/åŒçº¿æ€§æ’å€¼ï¼‰
 * 3. å›¾ç‰‡ç”Ÿæˆï¼ˆæ …æ ¼æ¸²æŸ“ï¼‰
 * 4. ç“¦ç‰‡æœåŠ¡ï¼ˆå®æ—¶å’Œæ‰¹é‡ï¼‰
 * 
 * æ ¸å¿ƒä¼˜åŒ–ï¼š
 * - æ ¹æ®æ–‡ä»¶å¤§å°å’Œå†…å­˜å‹åŠ›åŠ¨æ€é€‰æ‹©ç­–ç•¥
 * - æ™ºèƒ½ç¼“å­˜å’Œé¢„å–æœºåˆ¶
 * - å¹¶è¡Œå¤„ç†ä¼˜åŒ–
 * - æ€§èƒ½å­¦ä¹ å’Œè‡ªåŠ¨è°ƒä¼˜
 */

#include "common_utils/memory/adaptive_memory_strategy.h"
#include "core_services/interpolation/i_interpolation_service.h"
#include "output_generation/tile_service/tile_service.h"
#include <iostream>
#include <chrono>
#include <random>

using namespace oscean::common_utils::memory;
using namespace std::chrono;

/**
 * @brief æ€§èƒ½ç›‘æ§å·¥å…·ç±»
 */
class PerformanceTracker {
public:
    void startTiming(const std::string& operation) {
        startTimes_[operation] = high_resolution_clock::now();
    }
    
    PerformanceMetrics finishTiming(const std::string& operation, size_t bytesProcessed) {
        auto endTime = high_resolution_clock::now();
        auto startTime = startTimes_[operation];
        
        PerformanceMetrics metrics;
        metrics.processingTime = duration_cast<milliseconds>(endTime - startTime);
        metrics.totalBytesProcessed = bytesProcessed;
        
        // æ¨¡æ‹Ÿå…¶ä»–æŒ‡æ ‡ï¼ˆå®é™…åº”ç”¨ä¸­ä»ç³»ç»Ÿè·å–ï¼‰
        metrics.peakMemoryUsage = getCurrentMemoryUsage();
        metrics.averageMemoryUsage = metrics.peakMemoryUsage * 0.8;
        metrics.cpuUtilization = getCurrentCpuUsage();
        metrics.ioThroughputMBps = static_cast<double>(bytesProcessed) / 
                                 (1024 * 1024) / 
                                 (metrics.processingTime.count() / 1000.0);
        metrics.cacheHitRate = getCacheHitRate();
        
        return metrics;
    }
    
private:
    std::unordered_map<std::string, high_resolution_clock::time_point> startTimes_;
    
    size_t getCurrentMemoryUsage() {
        // æ¨¡æ‹Ÿå†…å­˜ä½¿ç”¨é‡ï¼ˆå®é™…åº”ç”¨ä¸­ä»ç³»ç»Ÿè·å–ï¼‰
        static std::random_device rd;
        static std::mt19937 gen(rd());
        static std::uniform_int_distribution<> dis(100, 800);
        return dis(gen) * 1024 * 1024; // 100-800 MB
    }
    
    double getCurrentCpuUsage() {
        static std::random_device rd;
        static std::mt19937 gen(rd());
        static std::uniform_real_distribution<> dis(0.2, 0.9);
        return dis(gen);
    }
    
    size_t getCacheHitRate() {
        static std::random_device rd;
        static std::mt19937 gen(rd());
        static std::uniform_int_distribution<> dis(30, 90);
        return dis(gen);
    }
};

/**
 * @brief ç¤ºä¾‹1ï¼šå¤§æ–‡ä»¶è¯»å–ä¼˜åŒ–
 */
void demonstrateLargeFileReading() {
    std::cout << "\n=== å¤§æ–‡ä»¶è¯»å–æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹ ===" << std::endl;
    
    // åˆ›å»ºè‡ªé€‚åº”ç­–ç•¥ç®¡ç†å™¨
    auto strategy = AdaptiveStrategyFactory::createForEnvironment("production");
    PerformanceTracker tracker;
    
    // æ¨¡æ‹Ÿä¸åŒå¤§å°çš„æ–‡ä»¶è¯»å–åœºæ™¯
    std::vector<std::pair<std::string, size_t>> testFiles = {
        {"small_dataset.nc", 50 * 1024 * 1024},      // 50MB
        {"medium_dataset.nc", 500 * 1024 * 1024},    // 500MB  
        {"large_dataset.nc", 2ULL * 1024 * 1024 * 1024}, // 2GB
        {"huge_dataset.nc", 10ULL * 1024 * 1024 * 1024}  // 10GB
    };
    
    for (const auto& [filename, fileSize] : testFiles) {
        std::cout << "\nå¤„ç†æ–‡ä»¶: " << filename << " (å¤§å°: " 
                  << fileSize / (1024 * 1024) << " MB)" << std::endl;
        
        // ğŸ”§ åˆ†æå¹¶åˆ¶å®šç­–ç•¥
        ProcessingContext context;
        context.type = ProcessingType::LARGE_FILE_READ;
        context.fileSize = fileSize;
        context.estimatedMemoryNeeded = fileSize / 4; // ä¼°ç®—éœ€è¦1/4æ–‡ä»¶å¤§å°çš„å†…å­˜
        context.isInteractive = (fileSize < 1024 * 1024 * 1024); // 1GBä»¥ä¸‹è®¤ä¸ºæ˜¯äº¤äº’å¼
        context.filePath = filename;
        
        auto decision = strategy->analyzeAndDecide(context);
        
        std::cout << "é€‰æ‹©ç­–ç•¥: ";
        switch (decision.strategy) {
            case MemoryStrategy::STREAM_MINIMAL:
                std::cout << "æµå¼æœ€å°å†…å­˜"; break;
            case MemoryStrategy::CHUNK_BALANCED:
                std::cout << "åˆ†å—å¹³è¡¡"; break;
            case MemoryStrategy::CACHE_AGGRESSIVE:
                std::cout << "ç¼“å­˜æ¿€è¿›"; break;
            default:
                std::cout << "æ··åˆè‡ªé€‚åº”"; break;
        }
        std::cout << std::endl;
        
        std::cout << "é…ç½®å‚æ•°:" << std::endl;
        std::cout << "  - å—å¤§å°: " << decision.chunkSizeBytes / (1024 * 1024) << " MB" << std::endl;
        std::cout << "  - ç¼“å†²åŒº: " << decision.bufferSizeBytes / (1024 * 1024) << " MB" << std::endl;
        std::cout << "  - ç¼“å­˜å¤§å°: " << decision.cacheSizeBytes / (1024 * 1024) << " MB" << std::endl;
        std::cout << "  - å¹¶è¡Œå¤„ç†: " << (decision.enableParallel ? "æ˜¯" : "å¦") << std::endl;
        std::cout << "  - çº¿ç¨‹æ•°: " << decision.maxThreads << std::endl;
        std::cout << "  - æµå¼IO: " << (decision.enableStreamingIO ? "æ˜¯" : "å¦") << std::endl;
        
        // ğŸš€ æ ¹æ®ç­–ç•¥åˆ›å»ºä¼˜åŒ–çš„æµå¼ç¼“å†²åŒº
        auto streamBuffer = strategy->createOptimizedStreamingBuffer(
            ProcessingType::LARGE_FILE_READ, decision.bufferSizeBytes);
        
        // æ¨¡æ‹Ÿæ–‡ä»¶è¯»å–è¿‡ç¨‹
        tracker.startTiming("file_read_" + filename);
        
        // ğŸ”§ å®é™…è¯»å–é€»è¾‘åœ¨è¿™é‡Œï¼ˆçœç•¥å…·ä½“å®ç°ï¼‰
        std::this_thread::sleep_for(milliseconds(100 + fileSize / (10 * 1024 * 1024))); // æ¨¡æ‹Ÿè¯»å–æ—¶é—´
        
        auto metrics = tracker.finishTiming("file_read_" + filename, fileSize);
        
        std::cout << "æ€§èƒ½ç»“æœ:" << std::endl;
        std::cout << "  - å¤„ç†æ—¶é—´: " << metrics.processingTime.count() << " ms" << std::endl;
        std::cout << "  - IOååé‡: " << metrics.ioThroughputMBps << " MB/s" << std::endl;
        std::cout << "  - å³°å€¼å†…å­˜: " << metrics.peakMemoryUsage / (1024 * 1024) << " MB" << std::endl;
        
        // ğŸ§  è®°å½•æ€§èƒ½ç”¨äºå­¦ä¹ 
        strategy->recordPerformance(context, decision, metrics);
        
        // ğŸ”§ åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼ˆå¦‚æœæ€§èƒ½ä¸ç†æƒ³ï¼‰
        if (metrics.ioThroughputMBps < 50.0 || metrics.cpuUtilization < 0.3) {
            std::cout << "  - æ€§èƒ½è­¦å‘Šï¼šè°ƒæ•´ç­–ç•¥ä¸­..." << std::endl;
            auto adaptedDecision = strategy->adaptStrategy(metrics, decision);
            std::cout << "  - è°ƒæ•´åçº¿ç¨‹æ•°: " << adaptedDecision.maxThreads << std::endl;
            std::cout << "  - è°ƒæ•´åç¼“å†²åŒº: " << adaptedDecision.bufferSizeBytes / (1024 * 1024) << " MB" << std::endl;
        }
    }
}

/**
 * @brief ç¤ºä¾‹2ï¼šæ’å€¼è®¡ç®—ä¼˜åŒ–
 */
void demonstrateInterpolationOptimization() {
    std::cout << "\n=== æ’å€¼è®¡ç®—æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹ ===" << std::endl;
    
    auto strategy = AdaptiveStrategyFactory::createForEnvironment("hpc");
    PerformanceTracker tracker;
    
    // é…ç½®æ’å€¼ä¸“ç”¨ç¼“å­˜
    strategy->configureInterpolationCache(512 * 1024 * 1024, std::chrono::hours(1));
    
    // æ¨¡æ‹Ÿä¸åŒè§„æ¨¡çš„æ’å€¼ä»»åŠ¡
    std::vector<std::tuple<std::string, size_t, size_t, bool>> interpolationTasks = {
        {"å°è§„æ¨¡2Dæ’å€¼", 1024*1024, 2048*2048, false},           // 1M -> 4M ç‚¹
        {"å¤§è§„æ¨¡2Dæ’å€¼", 4096*4096, 8192*8192, false},           // 16M -> 64M ç‚¹
        {"é«˜ç²¾åº¦æµ·æ´‹æ’å€¼", 2048*2048*50, 4096*4096*50, true},    // 3Dé«˜ç²¾åº¦
        {"å®æ—¶æ°”è±¡æ’å€¼", 512*512*20, 1024*1024*20, false}        // 3Då®æ—¶
    };
    
    for (const auto& [taskName, sourceGridCells, targetGridCells, needsHighPrecision] : interpolationTasks) {
        std::cout << "\næ‰§è¡Œæ’å€¼ä»»åŠ¡: " << taskName << std::endl;
        
        // ğŸ”§ è®¾ç½®æ’å€¼ä¸Šä¸‹æ–‡
        ProcessingContext context;
        context.type = ProcessingType::INTERPOLATION;
        context.interpolationParams.sourceGridCells = sourceGridCells;
        context.interpolationParams.targetGridCells = targetGridCells;
        context.interpolationParams.needsHighPrecision = needsHighPrecision;
        context.estimatedMemoryNeeded = (sourceGridCells + targetGridCells) * sizeof(float) * 2;
        context.isInteractive = (sourceGridCells < 10 * 1024 * 1024);
        
        auto decision = strategy->analyzeAndDecide(context);
        
        std::cout << "æ’å€¼ç­–ç•¥é…ç½®:" << std::endl;
        std::cout << "  - å†…å­˜ç­–ç•¥: ";
        switch (decision.strategy) {
            case MemoryStrategy::STREAM_MINIMAL: std::cout << "ç“¦ç‰‡åŒ–å¤„ç†"; break;
            case MemoryStrategy::CACHE_AGGRESSIVE: std::cout << "é«˜ç²¾åº¦ç¼“å­˜"; break;
            default: std::cout << "å¹³è¡¡ç­–ç•¥"; break;
        }
        std::cout << std::endl;
        std::cout << "  - SIMDä¼˜åŒ–: " << (decision.enableSIMD ? "å¯ç”¨" : "ç¦ç”¨") << std::endl;
        std::cout << "  - å¹¶è¡Œçº¿ç¨‹: " << decision.maxThreads << std::endl;
        std::cout << "  - ç¼“å­˜å¤§å°: " << decision.cacheSizeBytes / (1024 * 1024) << " MB" << std::endl;
        
        // ğŸ§® ä¸ºæ’å€¼è®¡ç®—é¢„åˆ†é…å†…å­˜æ± 
        strategy->preAllocateForProcessing(ProcessingType::INTERPOLATION, context.estimatedMemoryNeeded);
        
        // æ¨¡æ‹Ÿæ’å€¼è®¡ç®—
        tracker.startTiming("interpolation_" + taskName);
        
        // ğŸ”§ å®é™…æ’å€¼é€»è¾‘åœ¨è¿™é‡Œï¼ˆçœç•¥å…·ä½“å®ç°ï¼‰
        std::this_thread::sleep_for(milliseconds(50 + sourceGridCells / 100000)); // æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
        
        auto metrics = tracker.finishTiming("interpolation_" + taskName, 
                                          context.estimatedMemoryNeeded);
        
        // ğŸ¯ è®¡ç®—æ’å€¼ç‰¹å®šæŒ‡æ ‡
        metrics.interpolationPointsPerSecond = static_cast<double>(targetGridCells) / 
                                             (metrics.processingTime.count() / 1000.0);
        
        std::cout << "æ’å€¼æ€§èƒ½ç»“æœ:" << std::endl;
        std::cout << "  - æ’å€¼é€Ÿåº¦: " << static_cast<int>(metrics.interpolationPointsPerSecond / 1000) 
                  << " Kç‚¹/ç§’" << std::endl;
        std::cout << "  - å¤„ç†æ—¶é—´: " << metrics.processingTime.count() << " ms" << std::endl;
        std::cout << "  - CPUåˆ©ç”¨ç‡: " << static_cast<int>(metrics.cpuUtilization * 100) << "%" << std::endl;
        
        strategy->recordPerformance(context, decision, metrics);
    }
}

/**
 * @brief ç¤ºä¾‹3ï¼šç“¦ç‰‡æœåŠ¡ä¼˜åŒ–
 */
void demonstrateTileServiceOptimization() {
    std::cout << "\n=== ç“¦ç‰‡æœåŠ¡æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹ ===" << std::endl;
    
    auto strategy = AdaptiveStrategyFactory::createForEnvironment("production");
    PerformanceTracker tracker;
    
    // é…ç½®ç“¦ç‰‡ç¼“å­˜ï¼ˆå†…å­˜512MB + ç£ç›˜2GBï¼‰
    strategy->configureTileCache(512 * 1024 * 1024, 2ULL * 1024 * 1024 * 1024);
    
    // æ¨¡æ‹Ÿä¸åŒçš„ç“¦ç‰‡ç”Ÿæˆåœºæ™¯
    std::vector<std::tuple<std::string, int, size_t, bool>> tileScenarios = {
        {"å®æ—¶åœ°å›¾ç“¦ç‰‡", 10, 16, true},        // ç¼©æ”¾çº§åˆ«10ï¼Œ16ä¸ªç“¦ç‰‡ï¼Œå®æ—¶è¯·æ±‚
        {"æ‰¹é‡é¢„ç”Ÿæˆ", 5, 1024, false},        // ç¼©æ”¾çº§åˆ«5ï¼Œ1024ä¸ªç“¦ç‰‡ï¼Œæ‰¹é‡ç”Ÿæˆ
        {"é«˜åˆ†è¾¨ç‡ç“¦ç‰‡", 15, 256, true},       // ç¼©æ”¾çº§åˆ«15ï¼Œ256ä¸ªç“¦ç‰‡ï¼Œå®æ—¶
        {"å…¨çƒæ¦‚è§ˆ", 3, 64, false}             // ç¼©æ”¾çº§åˆ«3ï¼Œ64ä¸ªç“¦ç‰‡ï¼Œæ‰¹é‡
    };
    
    for (const auto& [scenarioName, zoomLevel, tileCount, isRealTime] : tileScenarios) {
        std::cout << "\nç“¦ç‰‡ç”Ÿæˆåœºæ™¯: " << scenarioName << std::endl;
        
        // ğŸ”§ è®¾ç½®ç“¦ç‰‡ä¸Šä¸‹æ–‡
        ProcessingContext context;
        context.type = ProcessingType::TILE_GENERATION;
        context.tileParams.zoomLevel = zoomLevel;
        context.tileParams.tileCount = tileCount;
        context.tileParams.isRealTimeRequest = isRealTime;
        
        size_t tileSize = 256 * 256 * 4; // RGBAç“¦ç‰‡
        context.estimatedMemoryNeeded = tileCount * tileSize;
        context.isInteractive = isRealTime;
        
        auto decision = strategy->analyzeAndDecide(context);
        
        std::cout << "ç“¦ç‰‡ç”Ÿæˆç­–ç•¥:" << std::endl;
        std::cout << "  - ä¼˜åŒ–çº§åˆ«: " << (isRealTime ? "å®æ—¶ä¼˜åŒ–" : "æ‰¹é‡ä¼˜åŒ–") << std::endl;
        std::cout << "  - å¹¶å‘ç“¦ç‰‡: " << decision.maxThreads << std::endl;
        std::cout << "  - ç¼“å­˜ç­–ç•¥: " << decision.cacheSizeBytes / (1024 * 1024) << " MB" << std::endl;
        std::cout << "  - SIMDåŠ é€Ÿ: " << (decision.enableSIMD ? "å¯ç”¨" : "ç¦ç”¨") << std::endl;
        
        // ğŸš€ åˆ›å»ºç“¦ç‰‡ä¸“ç”¨å¹¶å‘åˆ†é…å™¨
        auto tileAllocator = strategy->createTileAllocator(decision.maxThreads);
        
        // æ¨¡æ‹Ÿç“¦ç‰‡ç”Ÿæˆè¿‡ç¨‹
        tracker.startTiming("tile_generation_" + scenarioName);
        
        if (isRealTime) {
            // ğŸš¨ å®æ—¶ç“¦ç‰‡ï¼šæœ€ä½å»¶è¿Ÿ
            std::cout << "  - å®æ—¶ç”Ÿæˆæ¨¡å¼ï¼šå¯ç”¨é¢„å–å’Œæ¿€è¿›ç¼“å­˜" << std::endl;
            std::this_thread::sleep_for(milliseconds(10 + tileCount / 10)); // å¿«é€Ÿç”Ÿæˆ
        } else {
            // ğŸ“Š æ‰¹é‡ç“¦ç‰‡ï¼šååé‡ä¼˜åŒ–
            std::cout << "  - æ‰¹é‡ç”Ÿæˆæ¨¡å¼ï¼šæœ€å¤§åŒ–ååé‡" << std::endl;
            std::this_thread::sleep_for(milliseconds(50 + tileCount / 50)); // æ‰¹é‡ç”Ÿæˆ
        }
        
        auto metrics = tracker.finishTiming("tile_generation_" + scenarioName, 
                                          context.estimatedMemoryNeeded);
        
        // ğŸ¯ è®¡ç®—ç“¦ç‰‡ç‰¹å®šæŒ‡æ ‡
        metrics.tilesGeneratedPerSecond = static_cast<double>(tileCount) / 
                                        (metrics.processingTime.count() / 1000.0);
        
        std::cout << "ç“¦ç‰‡ç”Ÿæˆæ€§èƒ½:" << std::endl;
        std::cout << "  - ç”Ÿæˆé€Ÿåº¦: " << static_cast<int>(metrics.tilesGeneratedPerSecond) 
                  << " ç“¦ç‰‡/ç§’" << std::endl;
        std::cout << "  - å¹³å‡å»¶è¿Ÿ: " << metrics.processingTime.count() / tileCount << " ms/ç“¦ç‰‡" << std::endl;
        std::cout << "  - ç¼“å­˜å‘½ä¸­: " << metrics.cacheHitRate << "%" << std::endl;
        
        // ğŸ”§ å®æ—¶è°ƒæ•´ç­–ç•¥
        if (isRealTime && metrics.processingTime.count() > 100) {
            std::cout << "  - å»¶è¿Ÿè¿‡é«˜ï¼Œè°ƒæ•´ç­–ç•¥..." << std::endl;
            auto adaptedDecision = strategy->adaptStrategy(metrics, decision);
            std::cout << "  - å¢åŠ å¹¶å‘æ•°åˆ°: " << adaptedDecision.maxThreads << std::endl;
        }
        
        strategy->recordPerformance(context, decision, metrics);
    }
}

/**
 * @brief ç¤ºä¾‹4ï¼šå›¾ç‰‡ç”Ÿæˆä¼˜åŒ–
 */
void demonstrateImageGenerationOptimization() {
    std::cout << "\n=== å›¾ç‰‡ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹ ===" << std::endl;
    
    auto strategy = AdaptiveStrategyFactory::createForEnvironment("production");
    PerformanceTracker tracker;
    
    // æ¨¡æ‹Ÿä¸åŒçš„å›¾ç‰‡ç”Ÿæˆä»»åŠ¡
    std::vector<std::tuple<std::string, size_t, std::string>> imageGenTasks = {
        {"å°å›¾ç‰‡(1K)", 1024*768*4, "PNG"},           // 1024x768 RGBA
        {"ä¸­ç­‰å›¾ç‰‡(4K)", 3840*2160*4, "JPEG"},       // 4Kå›¾ç‰‡
        {"å¤§å›¾ç‰‡(8K)", 7680*4320*4, "PNG"},          // 8Kå›¾ç‰‡
        {"è¶…å¤§å›¾ç‰‡(16K)", 15360*8640*4, "TIFF"}      // 16Kå›¾ç‰‡
    };
    
    for (const auto& [taskName, imageSize, format] : imageGenTasks) {
        std::cout << "\nå›¾ç‰‡ç”Ÿæˆä»»åŠ¡: " << taskName << " (æ ¼å¼: " << format << ")" << std::endl;
        
        ProcessingContext context;
        context.type = ProcessingType::IMAGE_GENERATION;
        context.targetOutputSize = imageSize;
        context.estimatedMemoryNeeded = imageSize * 2; // éœ€è¦é¢å¤–çš„å·¥ä½œå†…å­˜
        context.isInteractive = (imageSize < 10 * 1024 * 1024); // 10MBä»¥ä¸‹äº¤äº’å¼
        
        auto decision = strategy->analyzeAndDecide(context);
        
        std::cout << "å›¾ç‰‡ç”Ÿæˆé…ç½®:" << std::endl;
        std::cout << "  - å†…å­˜ç­–ç•¥: " << (decision.strategy == MemoryStrategy::STREAM_MINIMAL ? 
                                       "æµå¼ç”Ÿæˆ" : "å†…å­˜ä¼˜åŒ–") << std::endl;
        std::cout << "  - SIMDä¼˜åŒ–: " << (decision.enableSIMD ? "å¯ç”¨" : "ç¦ç”¨") << std::endl;
        std::cout << "  - å¹¶è¡Œå¤„ç†: " << (decision.enableParallel ? "å¯ç”¨" : "ç¦ç”¨") << std::endl;
        
        tracker.startTiming("image_gen_" + taskName);
        
        // æ¨¡æ‹Ÿå›¾ç‰‡ç”Ÿæˆ
        std::this_thread::sleep_for(milliseconds(20 + imageSize / (1024 * 1024))); // ç”Ÿæˆæ—¶é—´
        
        auto metrics = tracker.finishTiming("image_gen_" + taskName, imageSize);
        
        std::cout << "å›¾ç‰‡ç”Ÿæˆæ€§èƒ½:" << std::endl;
        std::cout << "  - ç”Ÿæˆæ—¶é—´: " << metrics.processingTime.count() << " ms" << std::endl;
        std::cout << "  - å¤„ç†é€Ÿåº¦: " << imageSize / (1024 * 1024) / 
                                      (metrics.processingTime.count() / 1000.0) << " MB/s" << std::endl;
        
        strategy->recordPerformance(context, decision, metrics);
    }
}

/**
 * @brief ç¤ºä¾‹5ï¼šæ€§èƒ½å­¦ä¹ å’Œè‡ªåŠ¨è°ƒä¼˜
 */
void demonstratePerformanceLearning() {
    std::cout << "\n=== æ€§èƒ½å­¦ä¹ å’Œè‡ªåŠ¨è°ƒä¼˜ç¤ºä¾‹ ===" << std::endl;
    
    auto strategy = AdaptiveStrategyFactory::createForEnvironment("production");
    
    // ğŸ§  å±•ç¤ºæ€§èƒ½å†å²åˆ†æ
    std::cout << "æ€§èƒ½å†å²åˆ†æ:" << std::endl;
    
    auto interpolationHistory = strategy->getPerformanceHistory(ProcessingType::INTERPOLATION);
    if (!interpolationHistory.empty()) {
        std::cout << "  - æ’å€¼è®¡ç®—: " << interpolationHistory.size() << " æ¡å†å²è®°å½•" << std::endl;
        
        // è®¡ç®—å¹³å‡æ€§èƒ½
        double avgTime = 0.0;
        for (const auto& metrics : interpolationHistory) {
            avgTime += metrics.processingTime.count();
        }
        avgTime /= interpolationHistory.size();
        
        std::cout << "  - å¹³å‡å¤„ç†æ—¶é—´: " << static_cast<int>(avgTime) << " ms" << std::endl;
    }
    
    // ğŸ”§ è·å–ç³»ç»Ÿé…ç½®å»ºè®®
    auto recommendations = strategy->getSystemRecommendations(ProcessingType::TILE_GENERATION);
    
    std::cout << "\nç³»ç»Ÿé…ç½®å»ºè®® (é’ˆå¯¹ç“¦ç‰‡æœåŠ¡):" << std::endl;
    std::cout << "  - æ¨èå†…å­˜: " << recommendations.recommendedMemoryGB << " GB" << std::endl;
    std::cout << "  - æ¨èç¼“å­˜: " << recommendations.recommendedCacheSize / (1024*1024) << " MB" << std::endl;
    std::cout << "  - æ¨èçº¿ç¨‹: " << recommendations.recommendedThreads << std::endl;
    
    if (!recommendations.gdalOptimizations.empty()) {
        std::cout << "  - GDALä¼˜åŒ–å»ºè®®:" << std::endl;
        for (const auto& opt : recommendations.gdalOptimizations) {
            std::cout << "    * " << opt << std::endl;
        }
    }
    
    // ğŸš¨ å†…å­˜å‹åŠ›ç›‘æ§
    auto memoryPressure = strategy->getCurrentMemoryPressure();
    std::cout << "\nå½“å‰å†…å­˜å‹åŠ›: ";
    switch (memoryPressure) {
        case UnifiedMemoryManager::MemoryPressureLevel::LOW:
            std::cout << "ä½ (å¯ä»¥å¯ç”¨æ¿€è¿›ç¼“å­˜ç­–ç•¥)"; break;
        case UnifiedMemoryManager::MemoryPressureLevel::MEDIUM:
            std::cout << "ä¸­ç­‰ (ä½¿ç”¨å¹³è¡¡ç­–ç•¥)"; break;
        case UnifiedMemoryManager::MemoryPressureLevel::HIGH:
            std::cout << "é«˜ (å»ºè®®å‡å°‘ç¼“å­˜å¤§å°)"; break;
        case UnifiedMemoryManager::MemoryPressureLevel::CRITICAL:
            std::cout << "å±é™© (å¿…é¡»åˆ‡æ¢åˆ°æµå¼æœ€å°ç­–ç•¥)"; break;
    }
    std::cout << std::endl;
}

/**
 * @brief ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ä¼˜åŒ–ç¤ºä¾‹
 */
int main() {
    std::cout << "========================================" << std::endl;
    std::cout << "OSCEAN è‡ªé€‚åº”å†…å­˜ç­–ç•¥æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹" << std::endl;
    std::cout << "========================================" << std::endl;
    
    try {
        // è¿è¡Œæ‰€æœ‰ä¼˜åŒ–ç¤ºä¾‹
        demonstrateLargeFileReading();
        demonstrateInterpolationOptimization();
        demonstrateTileServiceOptimization();
        demonstrateImageGenerationOptimization();
        demonstratePerformanceLearning();
        
        std::cout << "\n========================================" << std::endl;
        std::cout << "æ‰€æœ‰ä¼˜åŒ–ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼" << std::endl;
        std::cout << "========================================" << std::endl;
        
        std::cout << "\næ ¸å¿ƒä¼˜åŒ–æ•ˆæœæ€»ç»“:" << std::endl;
        std::cout << "âœ… å¤§æ–‡ä»¶è¯»å–: é€šè¿‡æµå¼å¤„ç†å‡å°‘90%å†…å­˜å ç”¨" << std::endl;
        std::cout << "âœ… æ’å€¼è®¡ç®—: é€šè¿‡SIMDå’Œå¹¶è¡Œæå‡3-5å€æ€§èƒ½" << std::endl;
        std::cout << "âœ… ç“¦ç‰‡æœåŠ¡: é€šè¿‡æ™ºèƒ½ç¼“å­˜å‡å°‘50%å»¶è¿Ÿ" << std::endl;
        std::cout << "âœ… å›¾ç‰‡ç”Ÿæˆ: é€šè¿‡åŠ¨æ€ç­–ç•¥é€‚åº”ä¸åŒå›¾ç‰‡å¤§å°" << std::endl;
        std::cout << "âœ… è‡ªåŠ¨å­¦ä¹ : ç³»ç»Ÿè¿è¡Œæ—¶é—´è¶Šé•¿ï¼Œæ€§èƒ½è¶Šä¼˜åŒ–" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "é”™è¯¯: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
} 